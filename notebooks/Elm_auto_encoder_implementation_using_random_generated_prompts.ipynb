{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c08f72d60267491fb3aa93aa10879eaa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b0d7b6df35ba4ceca09206c3d5b4e4a3",
              "IPY_MODEL_9c970449c5cf4b84b2f295854ddfd1a5",
              "IPY_MODEL_917800e3a83b4b959a64b6d33d8b47ac"
            ],
            "layout": "IPY_MODEL_9a19d8ce560e4d9ea90944fd800318b5"
          }
        },
        "b0d7b6df35ba4ceca09206c3d5b4e4a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee3fd1babea147c3aee25251f127cef2",
            "placeholder": "​",
            "style": "IPY_MODEL_792ed1ba2c9f4e7e885d4f412c95ef87",
            "value": "Downloading (…)olve/main/vocab.json: 100%"
          }
        },
        "9c970449c5cf4b84b2f295854ddfd1a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b3ebf06f42df49859167323110531b61",
            "max": 961143,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0abed4f263224d8091d150d8bc673765",
            "value": 961143
          }
        },
        "917800e3a83b4b959a64b6d33d8b47ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d398f9788d6744e2a7b209179849f243",
            "placeholder": "​",
            "style": "IPY_MODEL_c1c913dc36ae4d6e980d4bac8df578ca",
            "value": " 961k/961k [00:00&lt;00:00, 1.38MB/s]"
          }
        },
        "9a19d8ce560e4d9ea90944fd800318b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee3fd1babea147c3aee25251f127cef2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "792ed1ba2c9f4e7e885d4f412c95ef87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b3ebf06f42df49859167323110531b61": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0abed4f263224d8091d150d8bc673765": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d398f9788d6744e2a7b209179849f243": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1c913dc36ae4d6e980d4bac8df578ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f335c7c6c2cc4197b383b23ea3c58e36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3b757d8d2d1c4d69ba8fb2b265ee78b1",
              "IPY_MODEL_99747c59cb224dc7800bfd339e4990ed",
              "IPY_MODEL_863dcfb74716406ea6548bba2d5d5707"
            ],
            "layout": "IPY_MODEL_c3e9b2f5052b41fb8d7f001189680120"
          }
        },
        "3b757d8d2d1c4d69ba8fb2b265ee78b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_542911b05ba049e3b69847a531cc3177",
            "placeholder": "​",
            "style": "IPY_MODEL_1a54578da6fd48f5abdb2b8e9d8a2b0d",
            "value": "Downloading (…)olve/main/merges.txt: 100%"
          }
        },
        "99747c59cb224dc7800bfd339e4990ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2fdaa95da5db46d6b0f5869d366ff4df",
            "max": 524619,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d179f2af66d046f996dc7cdd877812e4",
            "value": 524619
          }
        },
        "863dcfb74716406ea6548bba2d5d5707": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_62b80d08469240a3ab1a7b2511a88f5d",
            "placeholder": "​",
            "style": "IPY_MODEL_f4b40f4eea214d04a3334c1f49a8debe",
            "value": " 525k/525k [00:00&lt;00:00, 1.02MB/s]"
          }
        },
        "c3e9b2f5052b41fb8d7f001189680120": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "542911b05ba049e3b69847a531cc3177": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a54578da6fd48f5abdb2b8e9d8a2b0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2fdaa95da5db46d6b0f5869d366ff4df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d179f2af66d046f996dc7cdd877812e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "62b80d08469240a3ab1a7b2511a88f5d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4b40f4eea214d04a3334c1f49a8debe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "52b74d01e7f143a58c2ae6391f2712eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9416ed42975044599878ca9a93416a1b",
              "IPY_MODEL_747b03bbf3c943f797c79754540fcf22",
              "IPY_MODEL_519a72649ba947ec9e40d0ad8effc36a"
            ],
            "layout": "IPY_MODEL_7c0e8310b1f7437fad74f436f17e7f7a"
          }
        },
        "9416ed42975044599878ca9a93416a1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f584afb1858449e8d1f5bd22ac93c6a",
            "placeholder": "​",
            "style": "IPY_MODEL_759597a3eb7e4295840e948cb92c6c55",
            "value": "Downloading (…)cial_tokens_map.json: 100%"
          }
        },
        "747b03bbf3c943f797c79754540fcf22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4028c8f931104bf381012318942a8672",
            "max": 389,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ff0241fbcbd949c8ba3b7c7e4cd626ee",
            "value": 389
          }
        },
        "519a72649ba947ec9e40d0ad8effc36a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed42ee3f76ed4e5faaba4329085a32e1",
            "placeholder": "​",
            "style": "IPY_MODEL_0c5086ca5dee4ed2b206afbf55c215f9",
            "value": " 389/389 [00:00&lt;00:00, 22.6kB/s]"
          }
        },
        "7c0e8310b1f7437fad74f436f17e7f7a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f584afb1858449e8d1f5bd22ac93c6a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "759597a3eb7e4295840e948cb92c6c55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4028c8f931104bf381012318942a8672": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff0241fbcbd949c8ba3b7c7e4cd626ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ed42ee3f76ed4e5faaba4329085a32e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c5086ca5dee4ed2b206afbf55c215f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "22c8d9977cc8466f8fa11427008a2efb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_242c7e20435d445a81a1d00babd4263a",
              "IPY_MODEL_3531f29175d940dcaa998f049e67f024",
              "IPY_MODEL_9d4eee62adc047919e5ecae28bba24ba"
            ],
            "layout": "IPY_MODEL_b6aa99d5a9614b1ca4495478ce6f62a3"
          }
        },
        "242c7e20435d445a81a1d00babd4263a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c039f4c4eed6499ab2b6ff70088dcf95",
            "placeholder": "​",
            "style": "IPY_MODEL_fc60ee4a616245b6814638f00f9f78e9",
            "value": "Downloading (…)okenizer_config.json: 100%"
          }
        },
        "3531f29175d940dcaa998f049e67f024": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_786faeea4ff846628fcf2f20c384d8c2",
            "max": 905,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_68c5e47d5fa84d879bb306ecd3dafe5c",
            "value": 905
          }
        },
        "9d4eee62adc047919e5ecae28bba24ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_480cc2a90a534da88b6896ec000cb455",
            "placeholder": "​",
            "style": "IPY_MODEL_9d48b91e3e274595911cf7ec2105ee59",
            "value": " 905/905 [00:00&lt;00:00, 42.5kB/s]"
          }
        },
        "b6aa99d5a9614b1ca4495478ce6f62a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c039f4c4eed6499ab2b6ff70088dcf95": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc60ee4a616245b6814638f00f9f78e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "786faeea4ff846628fcf2f20c384d8c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68c5e47d5fa84d879bb306ecd3dafe5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "480cc2a90a534da88b6896ec000cb455": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d48b91e3e274595911cf7ec2105ee59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "05cb004f62b74a7bb9aa0f7daa11e54a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3fc21ed097db444ba5a71b004846a3a1",
              "IPY_MODEL_4a265f9b8d4b4a06b28e4bb1b454011a",
              "IPY_MODEL_adad1e937f1d4b4099519e6bd5bd349f"
            ],
            "layout": "IPY_MODEL_0a3989f27a2c473186d2aa766e3426e6"
          }
        },
        "3fc21ed097db444ba5a71b004846a3a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb58697135374c3489d12211e696b6b8",
            "placeholder": "​",
            "style": "IPY_MODEL_3e6aa35e446e432d93650482b13287aa",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "4a265f9b8d4b4a06b28e4bb1b454011a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_34a208f613404d079f54db3d85df0cca",
            "max": 4519,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_265cfa343d75440190e27616608e89a3",
            "value": 4519
          }
        },
        "adad1e937f1d4b4099519e6bd5bd349f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b31040ae2cce4393bad7f339b194f6cb",
            "placeholder": "​",
            "style": "IPY_MODEL_dffd074b54d947bd83c17978a518f0d0",
            "value": " 4.52k/4.52k [00:00&lt;00:00, 156kB/s]"
          }
        },
        "0a3989f27a2c473186d2aa766e3426e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb58697135374c3489d12211e696b6b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e6aa35e446e432d93650482b13287aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "34a208f613404d079f54db3d85df0cca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "265cfa343d75440190e27616608e89a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b31040ae2cce4393bad7f339b194f6cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dffd074b54d947bd83c17978a518f0d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "18e531164dc1439d83a583b13e2fae95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d4fdd76faf8d40bb91c0eb3defdf34be",
              "IPY_MODEL_98a8299c16064d50abc5d60a02657a15",
              "IPY_MODEL_be801617d58549e3862effeb038290f6"
            ],
            "layout": "IPY_MODEL_9bcbf6e0a4924a53a4fe7cc8815ef950"
          }
        },
        "d4fdd76faf8d40bb91c0eb3defdf34be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_06569807690241afa441e2f6d17e72fe",
            "placeholder": "​",
            "style": "IPY_MODEL_86e2d4db60d44ffb9cfdbaabab5b26de",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "98a8299c16064d50abc5d60a02657a15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d4784c5b7af45c49b7145984bea6481",
            "max": 1710671599,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f5c00e7c40b648fdbf727117935fb0bd",
            "value": 1710671599
          }
        },
        "be801617d58549e3862effeb038290f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ea3e1e858ffe4998a97a70261283e1c2",
            "placeholder": "​",
            "style": "IPY_MODEL_41d6c6034c4440b09907fa4316a7231e",
            "value": " 1.71G/1.71G [00:12&lt;00:00, 198MB/s]"
          }
        },
        "9bcbf6e0a4924a53a4fe7cc8815ef950": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06569807690241afa441e2f6d17e72fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86e2d4db60d44ffb9cfdbaabab5b26de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0d4784c5b7af45c49b7145984bea6481": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5c00e7c40b648fdbf727117935fb0bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ea3e1e858ffe4998a97a70261283e1c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41d6c6034c4440b09907fa4316a7231e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install openai-clip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yozDushcUkhN",
        "outputId": "dadb9d10-29e3-4a3a-ae94-7cc885af6e0c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.29.1-py3-none-any.whl (7.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m42.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m98.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.14.1 tokenizers-0.13.3 transformers-4.29.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai-clip\n",
            "  Downloading openai-clip-1.0.1.tar.gz (1.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting ftfy (from openai-clip)\n",
            "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from openai-clip) (2022.10.31)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-clip) (4.65.0)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.10/dist-packages (from ftfy->openai-clip) (0.2.6)\n",
            "Building wheels for collected packages: openai-clip\n",
            "  Building wheel for openai-clip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-clip: filename=openai_clip-1.0.1-py3-none-any.whl size=1368607 sha256=19c0fc218453db8033b644e8265a96cab19f914d7b8f2aa3133eb518a91a1f93\n",
            "  Stored in directory: /root/.cache/pip/wheels/08/77/8e/8d2f862df6bf7fb4e2007062d2cbaeae49862ec7b56d041229\n",
            "Successfully built openai-clip\n",
            "Installing collected packages: ftfy, openai-clip\n",
            "Successfully installed ftfy-6.1.1 openai-clip-1.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQ1qSlaCSqBg",
        "outputId": "c23dea49-d9c5-4e6c-e981-49562b299079"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "wasteland 2d pixel art cave\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "phrase_list = ['2d', 'pixel art', 'cave', 'scifi', 'side scrolling', 'chibi', 'waifu', 'space ship', 'desert', 'city', 'wasteland', 'mega structure', 'steal', 'stone', 'rock']\n",
        "\n",
        "def prompt_generator(phrase_list, prompt_word_length=32):\n",
        "    prompt = ''\n",
        "    while len(prompt) < prompt_word_length:\n",
        "        phrase = random.choice(phrase_list)\n",
        "        if len(prompt) + len(phrase) + 1 <= prompt_word_length:\n",
        "            prompt += phrase + ' '\n",
        "        else:\n",
        "            break\n",
        "    return prompt.strip()\n",
        "\n",
        "# example usage:\n",
        "prompt=prompt_generator(phrase_list) \n",
        "print(prompt_generator(phrase_list))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u7Jht2TnpWDP",
        "outputId": "ece77709-a45a-4055-d121-e0023b7fdb88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "scifi mega structure rock cave\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import clip\n",
        "import numpy as np\n",
        "\n",
        "use_cuda = torch.cuda.is_available()\n",
        "if use_cuda:\n",
        "    # Move tensors to CUDA device\n",
        "    device = torch.device('cuda:0')\n",
        "    print(f\"Using CUDA device: {torch.cuda.get_device_name(device)}\")\n",
        "else:\n",
        "    # Use CPU\n",
        "    device = torch.device('cpu')\n",
        "    print(\"Warning: CUDA not available, using CPU.\")\n",
        "\n",
        "# Load the CLIP model\n",
        "model, preprocess = clip.load(\"ViT-L/14\", device=device)\n",
        "\n",
        "# Tokenize and encode the prompt\n",
        "prompt = \"scifi mega structure rock cave\"\n",
        "tokens = clip.tokenize(prompt).to(device)\n",
        "print(\"Size of tokens:\", tokens.shape)\n",
        "with torch.no_grad():\n",
        "    text_features = model.encode_text(tokens).float()\n",
        "    text_features /= text_features.norm(dim=-1, keepdim=True)\n",
        "\n",
        "# Convert the embedding to a numpy array\n",
        "embedding = text_features.cpu().numpy()\n",
        "\n",
        "print(\"Text embedding shape:\",embedding.shape)  # should print (1, 768)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-9eq9c0caIf",
        "outputId": "06bb8361-989c-4fe3-bd34-2d40b54504c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████████████| 890M/890M [00:15<00:00, 61.7MiB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of tokens: torch.Size([1, 77])\n",
            "Text embedding shape: (1, 768)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run for obtaining random prompts, word embeddings and clip embeddings"
      ],
      "metadata": {
        "id": "Uw78nDSvHaYY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import torch\n",
        "import clip\n",
        "import random\n",
        "import numpy as np\n",
        "from typing import List\n",
        "from torch import nn\n",
        "from transformers import CLIPTokenizer, CLIPTextModel\n",
        "\n",
        "phrase_list = ['2d', 'pixel art', 'cave', 'scifi', 'side scrolling', 'chibi', 'waifu', 'space ship', 'desert', 'city', 'wasteland', 'mega structure', 'steal', 'stone', 'rock']\n",
        "\n",
        "N=500\n",
        "\n",
        "# Load the CLIP model\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model, preprocess = clip.load(\"ViT-L/14\", device=device)\n",
        "\n",
        "\n",
        "\n",
        "class CLIPTextEmbedder(nn.Module):\n",
        "    \"\"\"\n",
        "    ## CLIP Text Embedder\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, version: str = \"openai/clip-vit-large-patch14\", device=\"cuda:0\", max_length: int = 12):\n",
        "        \"\"\"\n",
        "        :param version: is the model version\n",
        "        :param device: is the device\n",
        "        :param max_length: is the max length of the tokenized prompt\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        # Load the tokenizer\n",
        "        self.tokenizer = CLIPTokenizer.from_pretrained(version)\n",
        "        print(self.tokenizer)\n",
        "        # Load the CLIP transformer\n",
        "        self.transformer = CLIPTextModel.from_pretrained(version).eval()\n",
        "\n",
        "        #self.device = device\n",
        "        self.device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "  \n",
        "        self.max_length = max_length\n",
        "\n",
        "    def forward(self, prompts: List[str]):\n",
        "        \"\"\"\n",
        "        :param prompts: are the list of prompts to embed\n",
        "        \"\"\"\n",
        "        # Tokenize the prompts\n",
        "        batch_encoding = self.tokenizer(prompts, truncation=True, max_length=self.max_length, return_length=True,\n",
        "                                        return_overflowing_tokens=False, padding=\"max_length\", return_tensors=\"pt\")\n",
        "        # Get token ids\n",
        "        tokens = batch_encoding[\"input_ids\"].to(self.device)\n",
        "        # Get CLIP embeddings\n",
        "        return self.transformer(input_ids=tokens).last_hidden_state\n",
        "\n",
        "def generate_prompts(num_prompts, phrase_list, prompt_word_length,x):\n",
        "    prompts = []\n",
        "    for i in range(num_prompts):\n",
        "        # Generate prompt\n",
        "        prompt = ''\n",
        "        while len(prompt) < prompt_word_length:\n",
        "            phrase = random.choice(phrase_list)\n",
        "            if len(prompt) + len(phrase) + 1 <= prompt_word_length:\n",
        "                prompt += phrase + ' '\n",
        "            else:\n",
        "                break\n",
        "        prompt = prompt.strip()\n",
        "        \n",
        "        # Get word embedding\n",
        "        with torch.no_grad():\n",
        "            tokens = clip.tokenize(prompt).to(device)\n",
        "            print(tokens.shape)\n",
        "            print(tokens)\n",
        "            print(type(tokens))\n",
        "            out = x.forward(prompt)\n",
        "            out=torch.flatten(out)\n",
        "            out=torch.unsqueeze(out,0)\n",
        "            print(out)\n",
        "            print(type(out))\n",
        "            print(out.shape)\n",
        "        #    text_features = model.encode_text(tokens).float()\n",
        "            print('Computing text embedding for Prompt'+str(i+1))\n",
        "            text_features = model.encode_text(tokens).float()\n",
        "            text_features /= text_features.norm(dim=-1, keepdim=True)\n",
        "            print(text_features.shape)\n",
        "            prompt_data = {\n",
        "            \"prompt\": prompt,\n",
        "            \"word_embedding\": out[0].tolist(),\n",
        "            \"clip_embedding\": text_features[0].tolist(),\n",
        "        }\n",
        "\n",
        "        # Append prompt, word embedding, and clip embedding to list\n",
        "        prompts.append(prompt_data)    \n",
        "    # Save prompts as JSON to file\n",
        "    with open(\"prompts_and_embeddings.json\", \"w\") as f:\n",
        "      json.dump(prompts, f)\n",
        "\n",
        "x = CLIPTextEmbedder()\n",
        "prompt_word_length=32\n",
        "generate_prompts(N, phrase_list,prompt_word_length,x)\n",
        "print('Process completed and dataset is generated')"
      ],
      "metadata": {
        "id": "9WBWA1-dim2-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "c08f72d60267491fb3aa93aa10879eaa",
            "b0d7b6df35ba4ceca09206c3d5b4e4a3",
            "9c970449c5cf4b84b2f295854ddfd1a5",
            "917800e3a83b4b959a64b6d33d8b47ac",
            "9a19d8ce560e4d9ea90944fd800318b5",
            "ee3fd1babea147c3aee25251f127cef2",
            "792ed1ba2c9f4e7e885d4f412c95ef87",
            "b3ebf06f42df49859167323110531b61",
            "0abed4f263224d8091d150d8bc673765",
            "d398f9788d6744e2a7b209179849f243",
            "c1c913dc36ae4d6e980d4bac8df578ca",
            "f335c7c6c2cc4197b383b23ea3c58e36",
            "3b757d8d2d1c4d69ba8fb2b265ee78b1",
            "99747c59cb224dc7800bfd339e4990ed",
            "863dcfb74716406ea6548bba2d5d5707",
            "c3e9b2f5052b41fb8d7f001189680120",
            "542911b05ba049e3b69847a531cc3177",
            "1a54578da6fd48f5abdb2b8e9d8a2b0d",
            "2fdaa95da5db46d6b0f5869d366ff4df",
            "d179f2af66d046f996dc7cdd877812e4",
            "62b80d08469240a3ab1a7b2511a88f5d",
            "f4b40f4eea214d04a3334c1f49a8debe",
            "52b74d01e7f143a58c2ae6391f2712eb",
            "9416ed42975044599878ca9a93416a1b",
            "747b03bbf3c943f797c79754540fcf22",
            "519a72649ba947ec9e40d0ad8effc36a",
            "7c0e8310b1f7437fad74f436f17e7f7a",
            "4f584afb1858449e8d1f5bd22ac93c6a",
            "759597a3eb7e4295840e948cb92c6c55",
            "4028c8f931104bf381012318942a8672",
            "ff0241fbcbd949c8ba3b7c7e4cd626ee",
            "ed42ee3f76ed4e5faaba4329085a32e1",
            "0c5086ca5dee4ed2b206afbf55c215f9",
            "22c8d9977cc8466f8fa11427008a2efb",
            "242c7e20435d445a81a1d00babd4263a",
            "3531f29175d940dcaa998f049e67f024",
            "9d4eee62adc047919e5ecae28bba24ba",
            "b6aa99d5a9614b1ca4495478ce6f62a3",
            "c039f4c4eed6499ab2b6ff70088dcf95",
            "fc60ee4a616245b6814638f00f9f78e9",
            "786faeea4ff846628fcf2f20c384d8c2",
            "68c5e47d5fa84d879bb306ecd3dafe5c",
            "480cc2a90a534da88b6896ec000cb455",
            "9d48b91e3e274595911cf7ec2105ee59",
            "05cb004f62b74a7bb9aa0f7daa11e54a",
            "3fc21ed097db444ba5a71b004846a3a1",
            "4a265f9b8d4b4a06b28e4bb1b454011a",
            "adad1e937f1d4b4099519e6bd5bd349f",
            "0a3989f27a2c473186d2aa766e3426e6",
            "cb58697135374c3489d12211e696b6b8",
            "3e6aa35e446e432d93650482b13287aa",
            "34a208f613404d079f54db3d85df0cca",
            "265cfa343d75440190e27616608e89a3",
            "b31040ae2cce4393bad7f339b194f6cb",
            "dffd074b54d947bd83c17978a518f0d0",
            "18e531164dc1439d83a583b13e2fae95",
            "d4fdd76faf8d40bb91c0eb3defdf34be",
            "98a8299c16064d50abc5d60a02657a15",
            "be801617d58549e3862effeb038290f6",
            "9bcbf6e0a4924a53a4fe7cc8815ef950",
            "06569807690241afa441e2f6d17e72fe",
            "86e2d4db60d44ffb9cfdbaabab5b26de",
            "0d4784c5b7af45c49b7145984bea6481",
            "f5c00e7c40b648fdbf727117935fb0bd",
            "ea3e1e858ffe4998a97a70261283e1c2",
            "41d6c6034c4440b09907fa4316a7231e"
          ]
        },
        "outputId": "16ef182d-fd38-4dc8-f1a7-d123ce0b1137"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|████████████████████████████████████████| 890M/890M [00:06<00:00, 141MiB/s]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/961k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c08f72d60267491fb3aa93aa10879eaa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/525k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f335c7c6c2cc4197b383b23ea3c58e36"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/389 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "52b74d01e7f143a58c2ae6391f2712eb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/905 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "22c8d9977cc8466f8fa11427008a2efb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CLIPTokenizer(name_or_path='openai/clip-vit-large-patch14', vocab_size=49408, model_max_length=77, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': AddedToken(\"<|startoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'eos_token': AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'unk_token': AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'pad_token': '<|endoftext|>'}, clean_up_tokenization_spaces=True)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/4.52k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "05cb004f62b74a7bb9aa0f7daa11e54a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/1.71G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "18e531164dc1439d83a583b13e2fae95"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at openai/clip-vit-large-patch14 were not used when initializing CLIPTextModel: ['vision_model.encoder.layers.21.layer_norm2.bias', 'vision_model.encoder.layers.11.self_attn.v_proj.weight', 'vision_model.encoder.layers.4.self_attn.out_proj.bias', 'vision_model.encoder.layers.21.mlp.fc1.weight', 'vision_model.encoder.layers.19.mlp.fc1.bias', 'vision_model.encoder.layers.15.layer_norm2.weight', 'vision_model.encoder.layers.4.mlp.fc1.weight', 'vision_model.encoder.layers.2.mlp.fc2.bias', 'vision_model.encoder.layers.15.self_attn.out_proj.bias', 'vision_model.encoder.layers.11.layer_norm2.bias', 'vision_model.encoder.layers.5.self_attn.k_proj.weight', 'vision_model.encoder.layers.10.self_attn.v_proj.weight', 'vision_model.encoder.layers.15.self_attn.q_proj.weight', 'vision_model.encoder.layers.16.mlp.fc2.weight', 'vision_model.encoder.layers.4.self_attn.q_proj.weight', 'vision_model.encoder.layers.18.self_attn.v_proj.bias', 'vision_model.encoder.layers.11.mlp.fc2.weight', 'vision_model.embeddings.class_embedding', 'vision_model.encoder.layers.21.layer_norm1.bias', 'vision_model.encoder.layers.4.self_attn.k_proj.bias', 'vision_model.encoder.layers.20.self_attn.k_proj.bias', 'vision_model.encoder.layers.2.mlp.fc2.weight', 'vision_model.encoder.layers.4.mlp.fc2.weight', 'vision_model.encoder.layers.13.mlp.fc1.weight', 'vision_model.encoder.layers.23.layer_norm1.weight', 'vision_model.encoder.layers.14.self_attn.out_proj.bias', 'vision_model.encoder.layers.5.mlp.fc1.bias', 'vision_model.encoder.layers.3.self_attn.k_proj.bias', 'vision_model.encoder.layers.8.self_attn.q_proj.weight', 'vision_model.encoder.layers.11.mlp.fc1.weight', 'vision_model.encoder.layers.7.layer_norm1.bias', 'vision_model.encoder.layers.21.self_attn.out_proj.bias', 'vision_model.encoder.layers.13.layer_norm1.weight', 'vision_model.encoder.layers.4.mlp.fc1.bias', 'vision_model.encoder.layers.10.self_attn.out_proj.bias', 'vision_model.encoder.layers.2.self_attn.out_proj.bias', 'vision_model.encoder.layers.2.layer_norm2.weight', 'vision_model.pre_layrnorm.bias', 'vision_model.encoder.layers.1.mlp.fc1.weight', 'vision_model.encoder.layers.18.layer_norm1.weight', 'vision_model.encoder.layers.18.layer_norm2.bias', 'vision_model.encoder.layers.6.self_attn.v_proj.bias', 'vision_model.encoder.layers.8.mlp.fc2.bias', 'vision_model.encoder.layers.22.mlp.fc1.bias', 'vision_model.encoder.layers.6.self_attn.k_proj.weight', 'vision_model.encoder.layers.6.layer_norm2.weight', 'vision_model.encoder.layers.1.mlp.fc1.bias', 'vision_model.encoder.layers.22.layer_norm1.bias', 'vision_model.encoder.layers.1.self_attn.q_proj.bias', 'vision_model.encoder.layers.23.self_attn.out_proj.bias', 'vision_model.encoder.layers.15.mlp.fc2.weight', 'vision_model.encoder.layers.12.self_attn.out_proj.weight', 'vision_model.encoder.layers.2.self_attn.k_proj.weight', 'vision_model.encoder.layers.4.layer_norm1.bias', 'vision_model.encoder.layers.3.self_attn.out_proj.bias', 'vision_model.encoder.layers.4.self_attn.v_proj.weight', 'vision_model.encoder.layers.18.mlp.fc2.weight', 'vision_model.encoder.layers.21.mlp.fc2.weight', 'vision_model.encoder.layers.1.layer_norm2.weight', 'vision_model.encoder.layers.7.self_attn.k_proj.bias', 'vision_model.encoder.layers.16.self_attn.k_proj.bias', 'vision_model.encoder.layers.5.mlp.fc1.weight', 'vision_model.encoder.layers.10.layer_norm2.weight', 'vision_model.encoder.layers.12.mlp.fc2.weight', 'vision_model.encoder.layers.13.self_attn.k_proj.weight', 'vision_model.encoder.layers.23.layer_norm2.weight', 'vision_model.encoder.layers.8.mlp.fc1.bias', 'vision_model.encoder.layers.18.mlp.fc1.weight', 'vision_model.encoder.layers.17.mlp.fc2.bias', 'vision_model.encoder.layers.7.layer_norm1.weight', 'vision_model.encoder.layers.22.self_attn.v_proj.bias', 'vision_model.encoder.layers.3.self_attn.v_proj.weight', 'vision_model.encoder.layers.3.mlp.fc2.weight', 'vision_model.encoder.layers.17.layer_norm2.weight', 'vision_model.encoder.layers.19.self_attn.v_proj.bias', 'vision_model.encoder.layers.5.mlp.fc2.bias', 'vision_model.encoder.layers.8.mlp.fc2.weight', 'vision_model.encoder.layers.10.mlp.fc2.bias', 'vision_model.encoder.layers.2.mlp.fc1.weight', 'vision_model.encoder.layers.3.mlp.fc1.weight', 'vision_model.encoder.layers.21.self_attn.out_proj.weight', 'vision_model.encoder.layers.19.mlp.fc1.weight', 'vision_model.encoder.layers.9.layer_norm2.bias', 'vision_model.encoder.layers.10.self_attn.q_proj.weight', 'vision_model.encoder.layers.12.mlp.fc1.weight', 'vision_model.encoder.layers.2.self_attn.v_proj.weight', 'vision_model.pre_layrnorm.weight', 'vision_model.encoder.layers.5.layer_norm1.bias', 'vision_model.encoder.layers.20.self_attn.q_proj.weight', 'vision_model.encoder.layers.1.layer_norm1.bias', 'vision_model.encoder.layers.5.layer_norm2.weight', 'vision_model.encoder.layers.19.layer_norm2.weight', 'vision_model.encoder.layers.7.self_attn.out_proj.bias', 'vision_model.encoder.layers.3.layer_norm1.bias', 'vision_model.encoder.layers.21.mlp.fc1.bias', 'vision_model.encoder.layers.20.self_attn.k_proj.weight', 'vision_model.encoder.layers.1.mlp.fc2.bias', 'vision_model.encoder.layers.15.layer_norm1.weight', 'vision_model.encoder.layers.3.layer_norm2.weight', 'vision_model.encoder.layers.4.self_attn.q_proj.bias', 'vision_model.encoder.layers.15.self_attn.v_proj.bias', 'vision_model.encoder.layers.6.mlp.fc1.bias', 'vision_model.encoder.layers.2.mlp.fc1.bias', 'vision_model.encoder.layers.3.mlp.fc1.bias', 'text_projection.weight', 'vision_model.encoder.layers.5.self_attn.k_proj.bias', 'vision_model.encoder.layers.22.mlp.fc1.weight', 'vision_model.encoder.layers.9.self_attn.out_proj.weight', 'vision_model.encoder.layers.21.self_attn.k_proj.weight', 'vision_model.encoder.layers.20.self_attn.q_proj.bias', 'vision_model.encoder.layers.18.mlp.fc2.bias', 'vision_model.encoder.layers.22.self_attn.out_proj.weight', 'vision_model.encoder.layers.23.mlp.fc2.bias', 'vision_model.encoder.layers.17.layer_norm2.bias', 'vision_model.encoder.layers.3.self_attn.out_proj.weight', 'vision_model.encoder.layers.8.mlp.fc1.weight', 'vision_model.encoder.layers.10.self_attn.q_proj.bias', 'vision_model.encoder.layers.10.layer_norm2.bias', 'vision_model.encoder.layers.22.self_attn.q_proj.weight', 'vision_model.encoder.layers.16.layer_norm1.weight', 'vision_model.encoder.layers.6.layer_norm1.bias', 'vision_model.encoder.layers.6.mlp.fc1.weight', 'vision_model.encoder.layers.12.layer_norm2.weight', 'vision_model.encoder.layers.5.layer_norm1.weight', 'vision_model.encoder.layers.12.layer_norm1.weight', 'vision_model.encoder.layers.14.mlp.fc1.weight', 'vision_model.encoder.layers.19.self_attn.out_proj.weight', 'vision_model.encoder.layers.11.layer_norm2.weight', 'vision_model.encoder.layers.1.mlp.fc2.weight', 'vision_model.encoder.layers.19.layer_norm1.bias', 'vision_model.encoder.layers.16.mlp.fc1.bias', 'vision_model.encoder.layers.20.self_attn.out_proj.weight', 'vision_model.encoder.layers.10.layer_norm1.bias', 'vision_model.encoder.layers.14.self_attn.v_proj.weight', 'vision_model.encoder.layers.12.self_attn.q_proj.bias', 'vision_model.encoder.layers.14.mlp.fc2.bias', 'vision_model.encoder.layers.20.mlp.fc2.bias', 'vision_model.encoder.layers.16.self_attn.q_proj.bias', 'vision_model.encoder.layers.0.self_attn.v_proj.bias', 'vision_model.encoder.layers.17.mlp.fc2.weight', 'vision_model.encoder.layers.23.self_attn.k_proj.weight', 'vision_model.encoder.layers.4.self_attn.k_proj.weight', 'vision_model.encoder.layers.18.self_attn.k_proj.bias', 'vision_model.encoder.layers.2.layer_norm2.bias', 'vision_model.encoder.layers.19.self_attn.k_proj.weight', 'vision_model.encoder.layers.12.self_attn.k_proj.bias', 'vision_model.encoder.layers.16.self_attn.out_proj.weight', 'vision_model.encoder.layers.18.layer_norm1.bias', 'vision_model.encoder.layers.1.self_attn.k_proj.weight', 'vision_model.encoder.layers.7.self_attn.q_proj.bias', 'vision_model.encoder.layers.10.layer_norm1.weight', 'vision_model.encoder.layers.9.mlp.fc2.weight', 'vision_model.encoder.layers.0.mlp.fc2.bias', 'vision_model.encoder.layers.3.self_attn.q_proj.weight', 'vision_model.encoder.layers.5.self_attn.q_proj.bias', 'vision_model.encoder.layers.12.self_attn.v_proj.bias', 'vision_model.encoder.layers.20.self_attn.v_proj.weight', 'vision_model.encoder.layers.22.self_attn.out_proj.bias', 'vision_model.encoder.layers.15.mlp.fc1.weight', 'vision_model.encoder.layers.13.layer_norm1.bias', 'vision_model.encoder.layers.10.self_attn.k_proj.bias', 'vision_model.encoder.layers.7.self_attn.v_proj.weight', 'vision_model.encoder.layers.21.mlp.fc2.bias', 'vision_model.encoder.layers.7.self_attn.v_proj.bias', 'vision_model.encoder.layers.17.layer_norm1.weight', 'vision_model.encoder.layers.16.mlp.fc2.bias', 'vision_model.encoder.layers.22.self_attn.k_proj.weight', 'vision_model.encoder.layers.7.self_attn.q_proj.weight', 'vision_model.encoder.layers.14.self_attn.k_proj.bias', 'vision_model.encoder.layers.21.self_attn.q_proj.weight', 'vision_model.encoder.layers.11.mlp.fc2.bias', 'vision_model.encoder.layers.1.layer_norm2.bias', 'vision_model.post_layernorm.bias', 'vision_model.encoder.layers.13.layer_norm2.weight', 'vision_model.encoder.layers.8.self_attn.q_proj.bias', 'vision_model.encoder.layers.3.layer_norm1.weight', 'vision_model.encoder.layers.7.self_attn.out_proj.weight', 'vision_model.encoder.layers.18.mlp.fc1.bias', 'vision_model.encoder.layers.8.self_attn.v_proj.weight', 'vision_model.encoder.layers.23.layer_norm2.bias', 'vision_model.encoder.layers.7.self_attn.k_proj.weight', 'vision_model.encoder.layers.20.mlp.fc2.weight', 'vision_model.encoder.layers.0.layer_norm1.bias', 'vision_model.encoder.layers.21.layer_norm2.weight', 'vision_model.encoder.layers.15.mlp.fc2.bias', 'vision_model.encoder.layers.23.self_attn.q_proj.bias', 'vision_model.encoder.layers.22.mlp.fc2.bias', 'vision_model.encoder.layers.18.self_attn.q_proj.bias', 'vision_model.encoder.layers.12.self_attn.out_proj.bias', 'vision_model.encoder.layers.15.self_attn.out_proj.weight', 'vision_model.encoder.layers.12.self_attn.v_proj.weight', 'vision_model.encoder.layers.9.self_attn.q_proj.weight', 'vision_model.encoder.layers.7.mlp.fc1.bias', 'vision_model.encoder.layers.5.self_attn.v_proj.weight', 'vision_model.encoder.layers.22.self_attn.q_proj.bias', 'vision_model.encoder.layers.4.layer_norm2.weight', 'vision_model.encoder.layers.9.self_attn.out_proj.bias', 'vision_model.encoder.layers.1.self_attn.out_proj.weight', 'vision_model.encoder.layers.21.self_attn.v_proj.weight', 'vision_model.encoder.layers.14.layer_norm2.weight', 'vision_model.encoder.layers.16.layer_norm2.bias', 'vision_model.encoder.layers.8.self_attn.out_proj.weight', 'vision_model.encoder.layers.8.self_attn.k_proj.weight', 'vision_model.encoder.layers.19.mlp.fc2.weight', 'vision_model.encoder.layers.20.self_attn.v_proj.bias', 'vision_model.encoder.layers.6.self_attn.out_proj.weight', 'vision_model.encoder.layers.9.self_attn.v_proj.bias', 'vision_model.encoder.layers.0.self_attn.q_proj.weight', 'vision_model.encoder.layers.23.mlp.fc1.bias', 'vision_model.encoder.layers.6.mlp.fc2.bias', 'vision_model.encoder.layers.23.self_attn.q_proj.weight', 'vision_model.encoder.layers.13.self_attn.q_proj.bias', 'vision_model.encoder.layers.6.layer_norm2.bias', 'logit_scale', 'vision_model.encoder.layers.5.self_attn.out_proj.weight', 'vision_model.encoder.layers.12.self_attn.k_proj.weight', 'vision_model.encoder.layers.21.layer_norm1.weight', 'vision_model.encoder.layers.2.self_attn.q_proj.weight', 'vision_model.encoder.layers.2.layer_norm1.bias', 'vision_model.encoder.layers.14.self_attn.q_proj.weight', 'vision_model.encoder.layers.13.mlp.fc2.weight', 'vision_model.encoder.layers.1.self_attn.k_proj.bias', 'vision_model.encoder.layers.6.self_attn.k_proj.bias', 'vision_model.encoder.layers.7.mlp.fc2.weight', 'vision_model.encoder.layers.18.layer_norm2.weight', 'vision_model.encoder.layers.16.self_attn.k_proj.weight', 'vision_model.encoder.layers.22.mlp.fc2.weight', 'vision_model.encoder.layers.12.mlp.fc1.bias', 'vision_model.encoder.layers.11.self_attn.q_proj.weight', 'vision_model.encoder.layers.0.self_attn.out_proj.bias', 'vision_model.encoder.layers.10.self_attn.out_proj.weight', 'vision_model.encoder.layers.2.self_attn.out_proj.weight', 'vision_model.encoder.layers.10.mlp.fc2.weight', 'vision_model.encoder.layers.10.mlp.fc1.weight', 'vision_model.encoder.layers.17.self_attn.k_proj.bias', 'vision_model.encoder.layers.9.self_attn.q_proj.bias', 'vision_model.encoder.layers.1.self_attn.v_proj.weight', 'vision_model.encoder.layers.2.self_attn.v_proj.bias', 'vision_model.encoder.layers.20.self_attn.out_proj.bias', 'vision_model.encoder.layers.14.mlp.fc2.weight', 'vision_model.encoder.layers.3.self_attn.q_proj.bias', 'vision_model.encoder.layers.14.self_attn.v_proj.bias', 'vision_model.encoder.layers.9.self_attn.v_proj.weight', 'vision_model.encoder.layers.14.mlp.fc1.bias', 'vision_model.encoder.layers.8.layer_norm1.bias', 'vision_model.encoder.layers.15.self_attn.q_proj.bias', 'vision_model.encoder.layers.2.self_attn.q_proj.bias', 'vision_model.encoder.layers.18.self_attn.v_proj.weight', 'vision_model.encoder.layers.7.mlp.fc1.weight', 'vision_model.encoder.layers.23.self_attn.k_proj.bias', 'vision_model.encoder.layers.12.layer_norm2.bias', 'vision_model.encoder.layers.8.layer_norm1.weight', 'vision_model.encoder.layers.14.self_attn.k_proj.weight', 'vision_model.encoder.layers.18.self_attn.out_proj.weight', 'vision_model.encoder.layers.15.self_attn.v_proj.weight', 'vision_model.encoder.layers.6.self_attn.v_proj.weight', 'vision_model.encoder.layers.19.self_attn.q_proj.bias', 'vision_model.encoder.layers.11.self_attn.out_proj.bias', 'vision_model.encoder.layers.3.self_attn.k_proj.weight', 'vision_model.encoder.layers.0.self_attn.k_proj.bias', 'vision_model.encoder.layers.1.self_attn.q_proj.weight', 'vision_model.encoder.layers.15.layer_norm2.bias', 'vision_model.encoder.layers.6.self_attn.q_proj.bias', 'vision_model.encoder.layers.13.self_attn.out_proj.bias', 'vision_model.encoder.layers.11.layer_norm1.weight', 'vision_model.encoder.layers.1.self_attn.v_proj.bias', 'vision_model.encoder.layers.4.layer_norm2.bias', 'vision_model.encoder.layers.6.mlp.fc2.weight', 'vision_model.encoder.layers.21.self_attn.q_proj.bias', 'vision_model.encoder.layers.20.layer_norm2.bias', 'vision_model.encoder.layers.10.mlp.fc1.bias', 'vision_model.encoder.layers.12.layer_norm1.bias', 'vision_model.encoder.layers.17.self_attn.out_proj.weight', 'vision_model.encoder.layers.11.layer_norm1.bias', 'vision_model.encoder.layers.11.self_attn.k_proj.bias', 'vision_model.encoder.layers.20.layer_norm2.weight', 'vision_model.encoder.layers.17.self_attn.k_proj.weight', 'vision_model.encoder.layers.6.self_attn.out_proj.bias', 'vision_model.encoder.layers.21.self_attn.k_proj.bias', 'vision_model.encoder.layers.0.self_attn.v_proj.weight', 'vision_model.encoder.layers.14.layer_norm1.weight', 'vision_model.encoder.layers.0.self_attn.q_proj.bias', 'vision_model.encoder.layers.17.self_attn.q_proj.bias', 'vision_model.encoder.layers.19.layer_norm2.bias', 'vision_model.encoder.layers.19.self_attn.k_proj.bias', 'vision_model.encoder.layers.13.mlp.fc1.bias', 'vision_model.encoder.layers.22.self_attn.k_proj.bias', 'vision_model.encoder.layers.18.self_attn.out_proj.bias', 'vision_model.encoder.layers.19.self_attn.out_proj.bias', 'vision_model.encoder.layers.5.mlp.fc2.weight', 'vision_model.encoder.layers.12.mlp.fc2.bias', 'vision_model.encoder.layers.22.layer_norm2.bias', 'vision_model.encoder.layers.22.layer_norm1.weight', 'vision_model.encoder.layers.19.self_attn.q_proj.weight', 'vision_model.encoder.layers.20.mlp.fc1.bias', 'vision_model.encoder.layers.11.mlp.fc1.bias', 'vision_model.encoder.layers.15.self_attn.k_proj.bias', 'vision_model.encoder.layers.0.mlp.fc1.weight', 'vision_model.encoder.layers.14.layer_norm1.bias', 'vision_model.encoder.layers.8.self_attn.v_proj.bias', 'vision_model.encoder.layers.5.self_attn.v_proj.bias', 'visual_projection.weight', 'vision_model.encoder.layers.16.self_attn.v_proj.weight', 'vision_model.encoder.layers.17.self_attn.q_proj.weight', 'vision_model.encoder.layers.11.self_attn.out_proj.weight', 'vision_model.encoder.layers.1.layer_norm1.weight', 'vision_model.encoder.layers.4.self_attn.v_proj.bias', 'vision_model.encoder.layers.20.layer_norm1.weight', 'vision_model.encoder.layers.9.mlp.fc1.weight', 'vision_model.encoder.layers.15.self_attn.k_proj.weight', 'vision_model.encoder.layers.9.self_attn.k_proj.bias', 'vision_model.encoder.layers.12.self_attn.q_proj.weight', 'vision_model.encoder.layers.3.layer_norm2.bias', 'vision_model.encoder.layers.13.self_attn.v_proj.weight', 'vision_model.encoder.layers.16.self_attn.out_proj.bias', 'vision_model.encoder.layers.1.self_attn.out_proj.bias', 'vision_model.encoder.layers.13.self_attn.v_proj.bias', 'vision_model.encoder.layers.18.self_attn.k_proj.weight', 'vision_model.encoder.layers.11.self_attn.v_proj.bias', 'vision_model.encoder.layers.11.self_attn.q_proj.bias', 'vision_model.encoder.layers.5.self_attn.q_proj.weight', 'vision_model.encoder.layers.7.layer_norm2.weight', 'vision_model.encoder.layers.13.self_attn.out_proj.weight', 'vision_model.encoder.layers.17.self_attn.v_proj.weight', 'vision_model.encoder.layers.20.mlp.fc1.weight', 'vision_model.encoder.layers.23.mlp.fc1.weight', 'vision_model.encoder.layers.10.self_attn.v_proj.bias', 'vision_model.encoder.layers.6.layer_norm1.weight', 'vision_model.encoder.layers.0.self_attn.k_proj.weight', 'vision_model.encoder.layers.0.self_attn.out_proj.weight', 'vision_model.encoder.layers.18.self_attn.q_proj.weight', 'vision_model.encoder.layers.13.mlp.fc2.bias', 'vision_model.encoder.layers.2.layer_norm1.weight', 'vision_model.encoder.layers.23.layer_norm1.bias', 'vision_model.encoder.layers.9.mlp.fc1.bias', 'vision_model.encoder.layers.0.mlp.fc1.bias', 'vision_model.encoder.layers.16.layer_norm1.bias', 'vision_model.encoder.layers.20.layer_norm1.bias', 'vision_model.encoder.layers.23.self_attn.v_proj.weight', 'vision_model.encoder.layers.3.mlp.fc2.bias', 'vision_model.encoder.layers.14.self_attn.q_proj.bias', 'vision_model.post_layernorm.weight', 'vision_model.encoder.layers.0.layer_norm2.weight', 'vision_model.encoder.layers.8.self_attn.out_proj.bias', 'vision_model.encoder.layers.17.mlp.fc1.bias', 'vision_model.encoder.layers.17.self_attn.out_proj.bias', 'vision_model.encoder.layers.16.mlp.fc1.weight', 'vision_model.encoder.layers.23.self_attn.out_proj.weight', 'vision_model.encoder.layers.0.mlp.fc2.weight', 'vision_model.encoder.layers.2.self_attn.k_proj.bias', 'vision_model.encoder.layers.8.self_attn.k_proj.bias', 'vision_model.encoder.layers.13.self_attn.k_proj.bias', 'vision_model.encoder.layers.23.mlp.fc2.weight', 'vision_model.encoder.layers.16.layer_norm2.weight', 'vision_model.encoder.layers.9.mlp.fc2.bias', 'vision_model.encoder.layers.14.self_attn.out_proj.weight', 'vision_model.encoder.layers.8.layer_norm2.weight', 'vision_model.encoder.layers.13.layer_norm2.bias', 'vision_model.embeddings.position_embedding.weight', 'vision_model.embeddings.position_ids', 'vision_model.encoder.layers.6.self_attn.q_proj.weight', 'vision_model.encoder.layers.15.mlp.fc1.bias', 'vision_model.encoder.layers.16.self_attn.q_proj.weight', 'vision_model.encoder.layers.7.layer_norm2.bias', 'vision_model.encoder.layers.16.self_attn.v_proj.bias', 'vision_model.encoder.layers.0.layer_norm1.weight', 'vision_model.encoder.layers.22.layer_norm2.weight', 'vision_model.encoder.layers.4.self_attn.out_proj.weight', 'vision_model.encoder.layers.5.self_attn.out_proj.bias', 'vision_model.encoder.layers.19.mlp.fc2.bias', 'vision_model.encoder.layers.22.self_attn.v_proj.weight', 'vision_model.encoder.layers.15.layer_norm1.bias', 'vision_model.embeddings.patch_embedding.weight', 'vision_model.encoder.layers.9.layer_norm1.weight', 'vision_model.encoder.layers.4.layer_norm1.weight', 'vision_model.encoder.layers.19.layer_norm1.weight', 'vision_model.encoder.layers.19.self_attn.v_proj.weight', 'vision_model.encoder.layers.17.mlp.fc1.weight', 'vision_model.encoder.layers.9.self_attn.k_proj.weight', 'vision_model.encoder.layers.10.self_attn.k_proj.weight', 'vision_model.encoder.layers.9.layer_norm2.weight', 'vision_model.encoder.layers.13.self_attn.q_proj.weight', 'vision_model.encoder.layers.9.layer_norm1.bias', 'vision_model.encoder.layers.11.self_attn.k_proj.weight', 'vision_model.encoder.layers.14.layer_norm2.bias', 'vision_model.encoder.layers.4.mlp.fc2.bias', 'vision_model.encoder.layers.17.self_attn.v_proj.bias', 'vision_model.encoder.layers.0.layer_norm2.bias', 'vision_model.encoder.layers.23.self_attn.v_proj.bias', 'vision_model.encoder.layers.3.self_attn.v_proj.bias', 'vision_model.encoder.layers.8.layer_norm2.bias', 'vision_model.encoder.layers.21.self_attn.v_proj.bias', 'vision_model.encoder.layers.7.mlp.fc2.bias', 'vision_model.encoder.layers.17.layer_norm1.bias', 'vision_model.encoder.layers.5.layer_norm2.bias']\n",
            "- This IS expected if you are initializing CLIPTextModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing CLIPTextModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Computing text embedding for Prompt167\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,   273,   323,  9068,  5285, 13241,   794, 49407,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ...,  0.2657, -0.8798, -1.3760]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt168\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 44035,  9654, 10181, 46551, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.6901,  0.0114, -0.7497]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt169\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  1145, 28889,  1305, 22306, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.5159,  0.1878, -0.9966]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt170\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 22306, 44035,  1145, 28889, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.7625,  0.0316, -1.1693]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt171\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 22306,  2441, 46551,  2138,  1158, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ...,  0.1024,  0.5540, -1.1702]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt172\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  9068,  5285,   273,   323,  1305, 46551, 49407,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ...,  0.6452, -0.9404, -0.4476]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt173\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 12230, 13241,   794,  1305, 46551, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ...,  0.5423, -0.6312, -1.0284]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt174\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 44035,  2172,  2138,  1158, 46551, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.5174, -0.3988, -0.2655]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt175\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 44035,  2172,  1305,  1305, 10181, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -2.3096,  0.0857, -0.1936]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt176\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 13241,   794, 12230,  7301, 46551, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.4875, -0.5902, -0.7636]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt177\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  7301,  2172, 46551,  2138,  1158, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.0783, -0.6165, -0.3290]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt178\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2441, 44035,  7301, 49407,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.0392, -0.3187, -0.2123]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt179\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 22306, 13241,   794,  2441, 13241,   794, 49407,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.6895,  0.5185, -1.6923]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt180\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 10181, 22306, 46551, 22306, 10181, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.2320,  0.0734, -1.2538]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt181\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 13241,   794, 10181, 44035, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -2.2718,  0.0682, -0.8366]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt182\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  9654, 12230,  9654,  9654,  2172, 22306, 49407,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.5974,  0.9450, -0.8382]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt183\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 10181, 46551, 22306, 12230, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.4075, -0.2475, -1.8796]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt184\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  7301,  2172,  2172,  1305, 13241,   794, 49407,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.7820, -0.4471, -0.5224]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt185\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 44035, 44035, 12230, 46551, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ...,  0.1325, -0.3383, -0.8836]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt186\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 46551, 22306,  1305, 22306, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.2948,  0.2996, -1.5129]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt187\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  9654,   273,   323,  2441,  1305, 46551, 49407,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ...,  0.7244, -1.2607, -1.0746]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt188\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2172,  9068,  5285, 12230,  1305, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.5360, -0.4748,  0.2486]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt189\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 13241,   794, 22306, 12230, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.3225,  0.2387, -1.6225]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt190\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  1145, 28889,  1145, 28889, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.1715,  0.3882, -0.7405]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt191\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 22306,  9068,  5285,  2172,  2172, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.5831, -0.2557, -0.3341]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt192\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  9068,  5285, 13241,   794,  7301, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.1138, -0.7472, -0.1720]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt193\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  9654,  9068,  5285, 49407,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.0768, -0.0219,  0.4644]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt194\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  1145, 28889, 10181, 49407,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -2.4258,  0.4592, -0.8081]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt195\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 12230,  2138,  1158, 13241,   794,   273,   323, 49407,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.3070, -0.6793, -0.9447]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt196\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 12230,  2172,  2441,  9654, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.3737,  0.0782, -0.3704]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt197\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  9068,  5285,  7301, 49407,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.7462, -0.7535,  1.0233]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt198\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 46551,  9068,  5285,  9654, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.2300, -0.1410, -0.1839]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt199\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,   273,   323,  9068,  5285, 46551,  1305, 49407,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ...,  0.6730, -1.2346, -1.3420]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt200\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2172, 22306,   273,   323, 44035, 22306, 49407,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.8378, -0.5281, -2.0314]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt201\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 44035, 10181,  9068,  5285, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.9034, -0.5010,  0.5008]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt202\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2138,  1158,  9068,  5285, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.0892, -0.5539,  0.5245]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt203\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  1145, 28889,  2172, 44035, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.5244, -0.7827, -0.8346]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt204\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 46551,  1305,  9654,  9068,  5285, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ...,  0.0484, -0.2790,  0.0739]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt205\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 44035,  2441, 13241,   794, 46551, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.2756, -0.3879, -1.2668]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt206\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 13241,   794, 13241,   794, 44035, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -2.2067, -0.1283, -0.7743]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt207\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 22306,  7301,  9068,  5285, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.5990,  0.0703, -0.4481]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt208\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  9068,  5285, 44035, 49407,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.5572, -0.4203,  0.2204]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt209\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  1145, 28889, 13241,   794, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.0894,  0.1998, -0.9874]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt210\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2138,  1158,  1145, 28889,  2172, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.4066, -0.4503, -0.3222]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt211\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,   273,   323,  9068,  5285,  2441,  7301, 49407,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.2064, -0.6208, -0.3270]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt212\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 44035,  1305,  2138,  1158,   273,   323, 49407,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.0213,  0.0102, -0.8156]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt213\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  9654,  2172, 22306,  2172,   273,   323, 46551, 49407,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ...,  0.0893, -0.4825, -1.3809]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt214\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2172,  7301,  2441, 12230,  2172, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.6965,  0.1735, -1.0773]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt215\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2441, 13241,   794, 44035,  2172, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.9993, -0.4041, -1.1895]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt216\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2172,  1305, 46551,  2441, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.7328, -1.1696, -0.0014]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt217\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 12230,   273,   323,  2172,  1145, 28889, 49407,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.2417, -0.8797, -0.6600]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt218\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  9654,  2138,  1158, 22306,  9654, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.4876,  0.6798, -1.1076]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt219\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  1145, 28889,  1305, 44035, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.4009,  0.1643, -0.3315]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt220\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  9068,  5285,  9068,  5285, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.0266, -0.6639,  1.0066]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt221\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2138,  1158,  2138,  1158, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.7047,  0.3912,  0.0175]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt222\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 12230, 12230,  2138,  1158, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.3265, -0.7289, -0.7509]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt223\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 13241,   794,  2138,  1158,  9654,  2441, 49407,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.5671,  0.9957, -0.8159]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt224\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  1145, 28889,  2138,  1158, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.8214,  0.2352, -0.8162]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt225\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 44035, 44035, 49407,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.8023, -0.5155,  0.0312]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt226\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 22306,  7301,  9654, 12230, 46551, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ...,  0.3844, -0.3370, -0.4807]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt227\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 22306, 10181,  2441, 10181, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.3866,  0.8123, -1.1891]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt228\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  1305,  9068,  5285,   273,   323,  1305, 49407,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ...,  0.2830, -1.1203,  0.6061]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt229\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 22306, 13241,   794, 22306, 46551, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ...,  0.4874, -0.1297, -1.2376]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt230\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 46551,  2138,  1158,  1305,   273,   323, 22306, 49407,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.2004, -0.3970, -1.7594]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt231\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  7301, 12230,  2441, 49407,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.4383,  0.1802, -0.4728]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt232\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 44035,  9654, 22306, 12230,   273,   323, 49407,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.5062, -0.4510, -1.3403]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt233\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 13241,   794,  7301, 22306,  9654, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.7476,  0.1383, -1.0990]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt234\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2138,  1158,  2441, 46551, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-3.8838e-01,  2.2944e-02, -5.2197e-02,  ...,  1.2178e-01,\n",
            "         -9.3574e-04, -1.2938e+00]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt235\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2138,  1158, 10181,  9068,  5285, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.5931,  0.1611,  0.3104]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt236\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2172,  1305,  7301, 13241,   794, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.9617, -0.9390, -0.4317]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt237\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,   273,   323,  1145, 28889, 44035, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.0827, -0.9940, -0.6231]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt238\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2441, 22306,  7301,  9654, 10181, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.5058,  0.7911, -0.8091]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt239\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 22306, 13241,   794,  1145, 28889, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.0226,  0.1423, -1.0699]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt240\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  1305,  2172, 13241,   794,   273,   323,  2172, 49407,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.9020, -0.5222, -0.7760]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt241\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  7301,  2138,  1158, 46551, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.7518, -0.7389,  0.3112]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt242\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  1305,  1305,  1145, 28889, 46551, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.2446, -0.6989, -0.9889]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt243\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  7301, 22306,  1305,  2172,  2441, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.0179,  0.3257, -0.7477]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt244\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2138,  1158, 46551,  1145, 28889, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.4439, -0.1813, -0.7542]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt245\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 12230,  9068,  5285, 10181, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.5911, -0.8286,  0.3253]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt246\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 12230, 12230,  1145, 28889, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.4458, -0.3242, -0.4182]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt247\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2441, 12230,   273,   323, 12230, 46551, 49407,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ...,  0.9190, -0.5883, -1.5323]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt248\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2138,  1158,  2172,  2138,  1158,  9654, 49407,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.8530,  0.0270,  0.2766]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt249\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2138,  1158,  9068,  5285, 46551, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.0393, -0.6156, -0.3999]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt250\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2172,  2441,  1305,  9654,  7301, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.5188, -0.0846, -0.1400]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt251\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 10181,  2138,  1158,  2441, 12230, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.1885,  0.6620, -0.5302]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt252\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,   273,   323, 10181,  2172,  7301, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.6490, -0.7841, -1.0548]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt253\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2172,  9654,  7301,  2441,  2441, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.2255,  0.2709, -0.6007]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt254\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,   273,   323, 44035,  1305, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.5602, -1.1807, -0.8018]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt255\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 13241,   794,  1145, 28889,   273,   323, 49407,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.6508,  0.0977, -0.6323]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt256\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  1305,  1305,  2172,  7301, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.9510, -0.0256,  0.5501]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt257\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2172,  9654,  9068,  5285,   273,   323, 49407,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.0882, -0.5478,  0.0540]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt258\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 13241,   794, 13241,   794, 44035, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -2.2067, -0.1283, -0.7743]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt259\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,   273,   323,  7301,  9654,  2138,  1158,  9654, 49407,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.2302, -0.1408, -0.7275]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt260\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 12230,  2441,  9654, 46551,  1305, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ...,  0.7861,  0.6594, -1.0410]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt261\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2138,  1158,   273,   323, 13241,   794, 49407,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.5337, -0.6344, -1.1454]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt262\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  9654, 44035, 12230,   273,   323,   273,   323,  9654, 49407,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.9151, -0.4141, -1.1295]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt263\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 46551,  2138,  1158,  9068,  5285, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.1591, -0.3153, -0.0708]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt264\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 10181, 10181,  2172,  2172,   273,   323, 10181, 49407,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -2.2637, -0.1499, -0.2430]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt265\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  7301,  2441,  2441,  1305, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.8293,  0.3212, -0.5254]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt266\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2441, 13241,   794, 22306, 46551, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ...,  0.2396, -0.1058, -1.5822]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt267\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,   273,   323,   273,   323,   273,   323,  7301,  9654, 49407,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.9503, -0.9770, -0.2833]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt268\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 46551,  7301, 10181, 22306, 46551, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.2870,  0.2322, -0.8439]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt269\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2172, 12230,  7301,  9654, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.2400, -0.0314, -0.6517]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt270\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  9654, 22306,  1145, 28889, 10181, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.9544,  0.5540, -1.5002]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt271\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  7301,  7301,  2138,  1158, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.3210, -0.0586,  0.6459]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt272\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,   273,   323,  9654,  1145, 28889,   273,   323, 46551, 49407,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.1985, -1.3058, -2.0380]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt273\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2172, 10181, 22306, 46551,  2441, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.4504,  0.1884, -1.2812]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt274\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  1145, 28889,  2138,  1158,  2441, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.8441,  0.5439, -0.5602]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt275\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 44035,  1145, 28889, 49407,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -2.2198,  0.0310, -0.9985]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt276\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2138,  1158, 10181, 12230, 46551, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ...,  0.0151,  0.2423, -0.7236]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt277\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 10181,  2172,  1145, 28889, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.5361, -0.0988, -1.0174]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt278\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  1305,  9654, 44035, 49407,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ...,  0.0604, -0.4015, -0.5848]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt279\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 22306,  9068,  5285,  2441,  1305, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ...,  0.2602, -0.1587, -0.4048]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt280\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2138,  1158,  9654, 22306, 13241,   794, 49407,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ...,  0.2494,  0.3149, -1.3209]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt281\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 13241,   794,   273,   323, 44035, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.3628, -0.9875, -1.0292]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt282\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,   273,   323, 10181,  2441,  9654, 13241,   794, 49407,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.4251, -0.2303, -0.3969]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt283\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  1145, 28889, 12230, 22306,  9654, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.3993, -0.2262, -0.8956]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt284\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 10181, 22306,  2441,  2441, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.0909,  0.7269, -0.8731]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt285\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  1145, 28889, 22306,  2172, 22306, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.0020, -0.4204, -0.6817]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt286\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 12230, 22306,   273,   323,  1145, 28889, 49407,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.2514, -0.6596, -1.0076]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt287\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 12230, 44035, 12230,  2441, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.1762,  0.3814, -1.2810]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt288\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 22306, 12230,  7301, 12230,  2441, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.5440,  0.2483, -0.8757]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt289\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2172, 46551, 12230,  1145, 28889, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.1443, -1.2380, -0.5630]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt290\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 46551, 12230,   273,   323,  2138,  1158, 49407,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ...,  0.1006, -1.0931, -1.5944]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt291\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 10181, 44035,  1305,  2138,  1158, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.6896,  0.8565, -0.7410]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt292\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  9068,  5285,  1145, 28889, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.8345,  0.0804, -0.2833]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt293\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  9654,  2138,  1158,  9068,  5285, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ...,  0.1827,  0.0186,  0.4135]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt294\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  9068,  5285,  1305, 49407,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ...,  0.0619, -0.3633,  0.8449]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt295\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  7301,  1305,  7301, 46551, 22306, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.0537, -0.6325, -0.8671]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt296\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  7301,  2172,  2441, 13241,   794, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.1822, -0.4400, -0.4679]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt297\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2172,  9654, 22306, 13241,   794,  9654, 49407,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.1080, -0.0154, -1.3114]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt298\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2138,  1158,  2138,  1158, 12230, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.6548, -0.1092, -0.5478]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt299\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 13241,   794,  2441,  9654,  2138,  1158, 49407,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.3991,  0.0604, -0.8651]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt300\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 13241,   794,  2441, 12230, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.4978,  0.3292, -1.3128]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt301\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  9068,  5285, 10181,  2172, 22306, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.8018,  0.1993, -1.0729]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt302\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2172, 12230,  9654, 10181, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.3787,  1.0251, -0.9169]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt303\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2138,  1158,   273,   323,  2441, 12230,  9654, 49407,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.3819, -0.6763, -1.2744]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt304\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  7301, 46551,  1145, 28889, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.6628, -0.9175, -0.4169]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt305\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  9654,  1145, 28889,   273,   323,  7301, 49407,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -2.0067, -0.7414, -0.2999]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt306\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 22306, 46551,  2138,  1158,  1305, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.0166,  0.6691, -1.1290]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt307\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2172,  1305,   273,   323,  2138,  1158, 49407,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.3379, -1.1911, -1.1309]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt308\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2138,  1158,   273,   323,  2441,  1305,  2441, 49407,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.1981, -0.4059, -1.3001]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt309\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 10181, 13241,   794,  2441,  1305,   273,   323, 49407,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.2507,  0.5150, -1.0124]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt310\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2172,   273,   323,   273,   323, 10181,  1305,  7301, 49407,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -2.0661, -0.3823,  0.0468]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt311\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 44035, 12230,  1145, 28889, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.5991, -0.1994, -0.3748]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt312\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 46551,  9068,  5285,  2138,  1158, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.2352, -0.2061, -0.1856]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt313\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 44035,  9068,  5285,  2172, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.3921, -0.1062,  0.8482]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt314\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 22306,  9654, 12230,  2172,  2172, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.3264,  0.4948, -0.7096]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt315\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  1305,  2138,  1158,  2172, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.5969,  0.7672,  0.3410]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt316\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  1305, 46551, 22306,  9654, 12230, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ...,  0.2975, -0.4302, -0.7831]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt317\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2441, 44035,  2441,  1305, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.2979,  0.1683, -0.5134]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt318\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  9654,  9654,  2172, 12230, 22306, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.1833,  0.4851, -0.7302]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt319\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 12230,  9654,  1145, 28889, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.8380, -0.1376, -1.1466]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt320\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 22306,  1305,   273,   323,  7301, 12230, 49407,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.7815, -0.8820, -0.3089]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt321\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2172,  1145, 28889, 44035, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.8390, -0.6216, -0.6878]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt322\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2441, 10181, 10181, 44035, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -2.5350,  0.8920, -0.2091]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt323\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 13241,   794, 10181, 22306,  7301, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.0782,  0.4572, -0.9539]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt324\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2441,  1305,   273,   323,  1145, 28889, 49407,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.4308,  0.0139, -0.2795]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt325\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 44035, 22306,  2441, 22306, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.5715,  0.4152, -1.1037]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt326\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  1145, 28889, 22306,   273,   323, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.1504, -0.7045, -1.4718]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt327\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  1305, 13241,   794,  2441, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.5945,  0.8806, -0.9303]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt328\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2138,  1158,  2441,  7301, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.1368, -0.0547, -0.1183]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt329\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 10181,  2138,  1158,  2138,  1158, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.1688,  1.0475,  0.2369]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt330\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 44035, 13241,   794, 13241,   794, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.4702,  0.0929, -0.7520]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt331\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  7301, 10181,  1305, 13241,   794, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.8775,  0.0520, -0.1513]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt332\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2138,  1158, 13241,   794,   273,   323, 49407,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.3582, -0.6352, -1.2259]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt333\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 22306,  1145, 28889, 46551, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.3554, -0.4060, -0.8074]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt334\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2172, 10181,  9068,  5285, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.7794, -0.2290,  0.0027]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt335\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  9068,  5285, 12230,  2441, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.5745,  0.4004, -0.5149]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt336\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 44035,  2441, 13241,   794, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.8480,  0.2272, -0.9041]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt337\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  9068,  5285, 22306, 49407,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ...,  0.6980,  0.0086, -0.8916]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt338\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2138,  1158, 13241,   794, 13241,   794, 49407,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.8535, -0.2407, -0.7977]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt339\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,   273,   323,  2172, 22306,  1145, 28889, 49407,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.1141, -0.8807, -1.7099]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt340\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 12230,  2138,  1158, 46551, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ...,  0.5731, -0.4241, -0.7831]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt341\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2441,  9654,  7301,  2138,  1158, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.3664,  0.0357,  0.3261]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt342\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 22306, 13241,   794, 44035, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.4698, -0.0406, -1.4070]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt343\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  9068,  5285,  2138,  1158,  2441, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.1371,  0.2287,  0.1878]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt344\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 22306,  9654, 46551,  1305,   273,   323, 46551, 49407,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ...,  0.7684, -0.6397, -1.6764]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt345\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2138,  1158, 46551,  2172,  9654,  2172, 49407,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.1444, -0.0024, -0.5322]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt346\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 46551,  9654,  1305,  9068,  5285, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ...,  0.3757, -0.1729,  0.1197]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt347\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2441,  9068,  5285, 10181, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.6259, -0.1728,  0.2882]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt348\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  7301, 22306,  1145, 28889, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.5688, -0.0790, -0.9082]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt349\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  1305, 10181, 44035, 12230, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.2285,  0.5802, -0.3987]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt350\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  9654,   273,   323,  9068,  5285, 46551, 49407,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ...,  1.0240, -1.3811, -0.6303]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt351\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 46551, 13241,   794,   273,   323, 46551, 12230, 49407,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ...,  0.4170, -0.9041, -1.3482]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt352\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,   273,   323,  2138,  1158, 44035, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.5125, -0.8582, -1.4917]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt353\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2172,   273,   323, 10181,  2172, 22306, 12230, 49407,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.3953,  0.3292, -1.8865]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt354\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 22306, 44035,  2441, 44035, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.9246,  0.2054, -1.0922]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt355\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 12230, 22306,  9654, 12230, 12230, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.5372,  0.0291, -0.9712]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt356\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,   273,   323,  9068,  5285,  2138,  1158, 49407,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ...,  0.0675, -0.7333, -0.7814]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt357\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 12230, 44035,  7301,  9654, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.7006, -0.6157, -0.5115]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt358\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  1305, 12230,  9654,  2441, 44035, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ...,  0.1101, -0.2697, -0.8972]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt359\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2441, 12230, 46551,  1305,  9654, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ...,  0.1431,  0.7171, -0.9736]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt360\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2172,  9654,  9068,  5285,  2441, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.2694,  0.5023,  0.4561]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt361\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 22306, 46551,  7301,  9654, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.5924,  0.1700, -1.0643]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt362\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  7301,   273,   323,   273,   323, 44035, 12230, 49407,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.6768, -1.7570, -0.2300]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt363\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  1145, 28889,  2138,  1158,  1305, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.5279, -0.0924, -0.5820]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt364\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  9654,  9654, 13241,   794,  9654, 10181, 49407,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.4665,  0.8469, -0.1076]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt365\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 10181, 10181,  2172,   273,   323,  2138,  1158, 49407,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.7114,  0.2995, -0.6239]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt366\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,   273,   323,  1145, 28889, 13241,   794, 49407,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.7917, -0.5222, -1.0641]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt367\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 12230,  2138,  1158,  2138,  1158, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.3430, -0.3913, -0.5934]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt368\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 12230,  1305, 46551, 44035, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ...,  0.5960, -1.1747, -0.8864]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt369\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2441,  2138,  1158,   273,   323, 46551, 46551, 49407,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ...,  0.6731, -0.6666, -1.3044]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt370\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  9068,  5285, 12230, 22306, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ...,  0.2096, -0.4002, -0.9128]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt371\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 13241,   794, 46551,  1145, 28889, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.4648, -0.1596, -0.9625]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt372\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2138,  1158, 12230,  1145, 28889, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.0258, -0.2767, -0.2050]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt373\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 10181,  9654,  1145, 28889,  9654, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.3677,  0.8523, -0.9665]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt374\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  1305,  9068,  5285,  9654, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ...,  0.1791,  0.3747,  0.5771]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt375\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  9654, 46551,  9654, 12230,   273,   323, 49407,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ...,  0.3255, -0.6240, -1.7515]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt376\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  9068,  5285, 46551,  2441, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ...,  0.0268, -0.1684,  0.2198]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt377\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 46551, 12230, 13241,   794,  2172, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.2822, -0.7174, -1.3260]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt378\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  7301, 22306,  7301, 49407,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.7401,  0.3423, -0.8407]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt379\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  1145, 28889, 12230,  2441, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.6572,  0.5636, -0.5932]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt380\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  9068,  5285,  2441, 13241,   794, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ...,  0.1842, -0.1795, -0.8304]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt381\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  9654, 12230, 12230, 13241,   794, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.2044, -0.1096, -0.8344]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt382\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 46551,  2138,  1158, 10181,   273,   323, 49407,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.6251,  0.2419, -1.4550]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt383\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 22306,  2138,  1158,  2138,  1158, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.2577,  0.4492, -0.5114]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt384\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 44035, 22306,  2138,  1158, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.4637,  0.3299, -1.3710]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt385\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 22306, 10181,  1145, 28889,  9654, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.7762,  0.7499, -1.1486]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt386\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2172,  7301,  2172, 22306, 12230, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.5133,  0.1269, -1.0536]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt387\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 46551,  2138,  1158, 13241,   794, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.0537, -0.1328, -0.9243]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt388\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2172,  2138,  1158,  2441, 22306, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.5063,  0.9252, -1.0852]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt389\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 12230, 13241,   794,   273,   323,  1305,   273,   323,  9654,\n",
            "         49407,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.0787, -0.4217, -1.0037]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt390\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 46551,  1305,  1305,  2441,  1305, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.1630,  0.5610, -1.0164]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt391\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2138,  1158, 46551,  1305,   273,   323,  2441, 49407,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ...,  0.1125, -0.3899, -1.5320]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt392\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2138,  1158,  7301, 12230,  7301, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.7129, -0.6842,  0.0593]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt393\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  9654, 44035,  7301,  9654,  1305, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.4598,  0.1182, -0.6784]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt394\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 12230, 12230,  1305, 44035,   273,   323, 49407,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.5759, -0.4829, -0.1989]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt395\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 22306,  1145, 28889,  7301, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.9250, -0.0500,  0.0269]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt396\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 46551,  1145, 28889, 49407,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-3.8838e-01,  2.2944e-02, -5.2197e-02,  ..., -9.5091e-01,\n",
            "          8.1420e-04, -1.1930e+00]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt397\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2441,  1305,  1305,  2172,  9654,  9654, 49407,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.2916,  0.6861, -0.4574]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt398\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,   273,   323,   273,   323,   273,   323,  2172,  9654, 46551,\n",
            "         49407,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ...,  0.6866, -0.9775, -0.4906]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt399\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2138,  1158, 46551, 22306,   273,   323, 49407,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ...,  0.7798, -0.9506, -1.7995]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt400\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2441,  2138,  1158, 44035, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.6118, -0.2429, -0.3179]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt401\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 44035,   273,   323, 46551,  2172, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.1074, -0.9668, -0.6911]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt402\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 10181,  1145, 28889, 49407,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -2.3405,  0.4148, -0.5403]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt403\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 13241,   794,  9654, 44035, 22306, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.3999,  0.0586, -1.6199]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt404\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 13241,   794,  2172, 10181,  1305, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.3309,  0.4503, -0.7381]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt405\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 12230,  2172,  9068,  5285,  2441, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.3389, -0.3601, -0.1912]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt406\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2172,  1145, 28889,  2441,  2172, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.3612, -0.0703, -1.1693]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt407\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2172,  9068,  5285, 49407,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.3722, -0.4590,  0.4931]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt408\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2138,  1158,  9068,  5285, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.0892, -0.5539,  0.5245]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt409\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  9068,  5285, 22306, 44035, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.4315, -0.3900, -0.7721]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt410\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  9654,  1305,  7301,  2172,  2172,  2172, 49407,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.7710, -0.5886,  0.1886]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt411\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  9068,  5285,  2441, 22306, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ...,  0.5105,  0.6115, -0.8520]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt412\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  1305,   273,   323,   273,   323, 44035, 10181, 49407,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.1871, -0.3095, -0.6619]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt413\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2441, 44035, 22306,  9654,   273,   323, 49407,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.2634, -0.2552, -1.3495]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt414\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 13241,   794,  2172,  2172,  2138,  1158, 49407,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.4535, -0.3763, -0.7549]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt415\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  9068,  5285,  2172, 44035, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.0057, -0.8321, -0.1306]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt416\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 44035, 13241,   794, 49407,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.0554,  0.2699, -0.7118]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt417\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 44035,  7301,  9654, 10181, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.6249,  0.5033,  0.0308]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt418\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  9654, 13241,   794,  1145, 28889, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.4691,  0.0896, -0.7442]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt419\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 10181, 46551,  1145, 28889, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.2736, -0.6201, -1.5777]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt420\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 10181,  2172,  2138,  1158,  2441, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.7219,  0.9642, -0.5669]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt421\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  1145, 28889,  2138,  1158, 10181, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.1292,  0.2406, -0.3330]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt422\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 12230,  7301, 12230,   273,   323, 22306, 49407,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.8175, -1.0184, -1.0775]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt423\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 46551, 12230,  7301, 44035, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.8393, -0.8227, -0.8142]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt424\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 44035,  9654, 10181, 49407,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.6311,  0.6312, -0.1377]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt425\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2172,  2441,  7301, 12230, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.5364, -0.0371,  0.0280]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt426\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  7301, 46551,  9654,  7301, 46551, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.1383, -0.5608,  0.2372]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt427\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 13241,   794, 44035, 13241,   794, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -2.0403, -0.0726, -1.0341]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt428\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 12230,  2172,  9068,  5285, 46551, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ...,  0.2040, -0.9419, -0.1105]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt429\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 44035,  2138,  1158, 12230, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.8430,  0.1320, -0.2400]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt430\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  7301, 46551,  2172, 13241,   794, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.4823, -0.6292, -0.3598]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt431\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  1305,  2172,  7301,  1145, 28889, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.5252,  0.0190,  0.0647]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt432\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2172,  1145, 28889,  2138,  1158, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.9262, -0.2030, -0.6304]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt433\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  9068,  5285, 22306, 46551,  1305, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ...,  0.6428, -0.1976, -0.7031]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt434\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,   273,   323, 12230, 10181, 46551,  2172, 49407,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ...,  0.4326, -1.2577, -1.9199]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt435\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  7301,  9654, 46551,  9654,  2441, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.6334,  0.6182,  0.1513]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt436\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 22306, 44035,  1305,  9654, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.7147,  0.1888, -1.0229]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt437\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 44035,  1145, 28889, 49407,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -2.2198,  0.0310, -0.9985]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt438\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2138,  1158,  2172, 13241,   794, 22306, 49407,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.4969,  0.1380, -1.0252]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt439\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  1305, 10181, 12230,  2138,  1158,   273,   323, 49407,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.3399,  0.0808, -0.6558]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt440\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,   273,   323, 46551, 10181,  2441,  1305, 46551, 49407,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ...,  0.6279, -0.3282, -1.3874]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt441\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2172, 12230, 13241,   794, 44035, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.5466, -0.6491, -1.0612]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt442\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2172,  2138,  1158,  2441, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.8794,  0.2464, -0.3007]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt443\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 13241,   794, 22306,  9654,  1305, 12230, 49407,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ...,  0.0956, -0.0791, -0.9970]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt444\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  1145, 28889, 46551, 44035, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.6751, -1.1014, -0.9590]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt445\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,   273,   323, 46551,  7301,  9654,  1305,  2172, 49407,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.2730, -0.4050, -1.2850]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt446\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2138,  1158,  1305,  9068,  5285, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.0571, -0.3926,  0.1618]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt447\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  1305, 22306,  9654,   273,   323,  2138,  1158, 49407,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ...,  0.4467, -0.6092, -1.1374]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt448\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 44035, 13241,   794, 12230, 22306, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.5350, -0.0332, -1.3476]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt449\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  1145, 28889,   273,   323, 46551, 22306, 49407,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.4750, -1.0340, -1.3324]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt450\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2138,  1158,   273,   323,  2441, 46551,   273,   323,   273,\n",
            "           323, 49407,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ...,  0.6555, -0.6868, -1.6009]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt451\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2441,  2441,  9068,  5285,  1305, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.1968,  0.1550,  0.3899]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt452\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 22306, 44035, 10181, 22306, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.5896,  0.4550, -1.5878]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt453\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2138,  1158,  2138,  1158, 13241,   794, 49407,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.7091, -0.1626, -0.8060]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt454\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2138,  1158,  9068,  5285, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.0892, -0.5539,  0.5245]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt455\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  1145, 28889,  7301,  7301, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -2.2134,  0.2990,  0.2482]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt456\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2172,  1305,  7301, 46551,  2172, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.9117, -1.5453,  0.5796]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt457\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2441, 44035,  7301,  7301, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.4055, -0.1266,  0.0215]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt458\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  9654,  9068,  5285,  2441,  1305, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.2221, -0.0098,  0.0432]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt459\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,   273,   323, 22306, 44035,   273,   323, 49407,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.5014, -0.5032, -1.1910]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt460\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  1145, 28889,  2138,  1158, 22306, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.3843,  0.1491, -1.0046]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt461\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  1305, 10181,  7301, 10181,  1305, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.9501,  0.2486,  1.3072]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt462\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  9068,  5285, 10181,   273,   323, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.7140, -0.5327, -0.6225]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt463\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  1305,  2172,  1145, 28889,   273,   323, 49407,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.5298, -0.2417,  0.3613]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt464\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  7301, 13241,   794, 10181, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.5794, -0.2063, -0.3687]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt465\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2172, 12230, 10181, 44035, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -2.3816,  0.0327, -0.9380]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt466\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 44035, 12230, 22306, 10181, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.2023,  0.3047, -1.1889]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt467\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 22306,   273,   323,  1145, 28889,  2441, 49407,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.4063, -0.4698, -1.2764]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt468\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 10181, 44035,   273,   323,  2138,  1158, 49407,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -2.7933,  0.3033, -0.7611]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt469\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2172,  7301,  1145, 28889, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -2.1310, -0.2091, -1.0245]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt470\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 13241,   794,  9068,  5285, 12230, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.6930, -0.5270, -0.5935]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt471\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  9654,  7301,  9068,  5285,  2172, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.1438,  0.3814,  0.8230]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt472\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2172,  9654,  7301,  9654, 46551, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.6218, -0.4464, -0.1241]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt473\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2138,  1158,  2441,  1145, 28889, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.2360,  0.3003, -0.5127]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt474\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  1145, 28889, 10181,  7301, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -2.5536,  0.6584,  0.1974]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt475\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  7301, 46551, 44035,  7301, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.4979, -0.7976,  0.5591]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt476\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  9068,  5285, 44035,  1305, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.4408, -0.4713,  0.2777]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt477\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  1145, 28889,  9654,  9654, 10181, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.3892,  0.8860, -0.5160]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt478\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2138,  1158,  2441,  2138,  1158, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.9168,  0.4896,  0.0256]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt479\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  9068,  5285,  1145, 28889, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.8345,  0.0804, -0.2833]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt480\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2441,  1305, 12230,  7301,   273,   323, 49407,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.0655, -0.8703, -0.5862]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt481\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  1145, 28889,  9068,  5285, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.8064,  0.1896, -0.1480]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt482\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 13241,   794, 22306,  1305, 22306, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.1031,  0.3217, -1.4285]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt483\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  7301, 10181, 13241,   794,   273,   323, 10181, 49407,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -2.0912, -0.3863, -1.0423]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt484\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 22306,  1145, 28889,   273,   323, 10181, 49407,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.6997, -0.3990, -1.2541]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt485\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  9068,  5285,  9068,  5285, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.0266, -0.6639,  1.0066]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt486\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2138,  1158,  9068,  5285,  1305, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.3754, -0.1937,  0.0758]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt487\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2138,  1158, 13241,   794,   273,   323,   273,   323, 49407,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.5039, -0.6399, -1.2522]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt488\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 46551, 12230, 12230, 12230,  2441, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ...,  0.2850, -0.3678, -1.8335]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt489\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 22306,  1305, 10181,  9068,  5285, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.2015,  0.2221, -0.6985]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt490\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  9068,  5285, 22306, 49407,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ...,  0.6980,  0.0086, -0.8916]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt491\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 46551, 44035,   273,   323, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.4881, -0.9246, -1.5981]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt492\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  9654,  2138,  1158,  9654,  2441, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.4104,  1.6162, -0.4713]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt493\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 13241,   794, 46551,  7301, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.8407, -0.0298, -0.6873]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt494\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 10181,  7301,  9068,  5285, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.4675, -0.5708,  0.7851]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt495\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  7301, 44035, 13241,   794,  1305, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.1635, -0.7359, -0.5167]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt496\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  9654, 13241,   794, 22306,  1305, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.3227,  0.2929, -1.4009]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt497\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 12230,  1145, 28889,  1305,  1305, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ...,  0.0155, -0.0730,  0.4534]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt498\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2172,  1145, 28889, 10181, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -2.0899,  0.2262, -1.3645]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt499\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  9654,  2441,  2138,  1158, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.0798,  0.8848, -0.3132]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt500\n",
            "torch.Size([1, 768])\n",
            "Process completed and dataset is generated\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Declare a variable\n",
        "a = torch.tensor([2, 3, 4, 5])\n",
        "# Using unsqueeze() method to add dimension\n",
        "print(a.shape)\n",
        "m=torch.unsqueeze(a, 0)\n",
        "# Print output\n",
        "print(m.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UNdGVJw2Ncvo",
        "outputId": "f962740a-4ad3-4d73-db9b-a481d0b7adc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4])\n",
            "torch.Size([1, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lXoU-XhmrTP_",
        "outputId": "4c4164ce-dae3-4af8-c78c-85a124ecd489"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Elm auto-encoder implementation"
      ],
      "metadata": {
        "id": "T6FB9T_NF8HI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import json\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "\n",
        "class ELMAutoEncoder(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size, batch_size=1, use_gpu=True):\n",
        "        super(ELMAutoEncoder, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.batch_size = batch_size\n",
        "        self.use_gpu = use_gpu\n",
        "        if self.use_gpu and torch.cuda.is_available():\n",
        "            self.device = torch.device(\"cuda\")\n",
        "        else:\n",
        "            self.device = torch.device(\"cpu\")\n",
        "            print(\"Warning: CUDA not available, using CPU.\")\n",
        "        self.set_random_seed()    \n",
        "        self.weight = nn.Parameter(torch.randn(input_size, hidden_size, dtype=torch.float, device=self.device))\n",
        "        self.bias = nn.Parameter(torch.randn(hidden_size, device=self.device))\n",
        "        self.beta = nn.Parameter(torch.randn(hidden_size, output_size, device=self.device))\n",
        "        self.activation_hidden = nn.ReLU()\n",
        "        self.activation_output = nn.Identity()\n",
        "        \n",
        "    def forward(self, x):\n",
        "        h = self.activation_hidden(x @ self.weight + self.bias)       \n",
        "        y_pred = torch.sigmoid(h @ self.beta)  # apply sigmoid to output\n",
        "        return y_pred\n",
        "\n",
        "    def set_random_seed(self):\n",
        "        seed = int(time.time())\n",
        "        torch.manual_seed(seed)\n",
        "        np.random.seed(seed)\n",
        "    \n",
        "    def fit(self, x_train,targets_train, n_neurons):\n",
        "        H = self.activation_hidden(torch.matmul(x_train.float(), self.weight.float()) + self.bias.float())\n",
        "     #  H = self.activation_hidden(torch.matmul(x_train.float(), self.weight) + self.bias)\n",
        "        print('output of hiddenlayer',H.shape)\n",
        "        H_inv = torch.pinverse(H)\n",
        "\n",
        "        beta = torch.matmul(H_inv, targets_train.float())\n",
        "\n",
        "        self.beta = nn.Parameter(beta)\n",
        "        self.output_weight = nn.Parameter(self.beta)\n",
        "        print('output weight matrix',self.output_weight.shape)\n",
        "        self.bias = nn.Parameter(torch.zeros((n_neurons,)))\n",
        "        return self\n",
        "    \n",
        "    def encode(self, x):\n",
        "       # h = self.activation_hidden(x.float() @ self.weight.t())\n",
        "        print('input to encoder',x.shape)\n",
        "        h=self.activation_hidden(torch.matmul(x.float(), self.weight.float()) + self.bias.float())\n",
        "        return h\n",
        "    \n",
        "    def decode(self, h):\n",
        "        x_pred = self.activation_output(h @ self.output_weight)\n",
        "        return x_pred\n",
        "    \n",
        "    def clear_memory(self):\n",
        "        if self.use_gpu and torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()\n",
        "        else:\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "def reconstruction_error(model,data,targets_train):\n",
        "    with torch.no_grad():\n",
        "        encoded = model.encode(data)\n",
        "        print('encoded.shape',encoded.shape)\n",
        "        decoded = model.decode(encoded)\n",
        "        print('decoded',decoded.shape)\n",
        "        mse_loss = nn.MSELoss()(decoded, targets_train)\n",
        "        cos_sim = cosine_similarity(targets_train.reshape(targets_train.shape[0], -1), decoded.reshape(decoded.shape[0], -1))\n",
        "        cos_dis=1 - cos_sim.mean()\n",
        "        return mse_loss.item(),cos_dis\n",
        "\n",
        "def load_prompts(file_path):\n",
        "    with open(file_path) as f:\n",
        "        prompts = json.load(f)\n",
        "    return prompts\n",
        "\n",
        "def prepare_data(prompts):\n",
        "    text_features = []\n",
        "    for prompt in prompts:\n",
        "        text_feature = np.array(prompt['word_embedding'])\n",
        "        text_features.append(text_feature)\n",
        "    return text_features\n",
        "\n",
        "def prepare_targets(prompts):\n",
        "    clip_embeddings = []\n",
        "    for prompt in prompts:\n",
        "        clip_embedding = np.array(prompt['clip_embedding'])\n",
        "        clip_embeddings.append(clip_embedding)\n",
        "    return clip_embeddings\n",
        "\n",
        "\n",
        "\n",
        "prompts = load_prompts('./prompts_and_embeddings.json')\n",
        "\n",
        "# Prepare data and targets\n",
        "data = prepare_data(prompts)\n",
        "targets = prepare_targets(prompts)\n",
        "hidden_size=500\n",
        "# Convert to PyTorch tensors\n",
        "\n",
        "\n",
        "# Split the data into train and test sets\n",
        "data_train, data_test, targets_train, targets_test = train_test_split(data, targets, test_size=0.2, random_state=42)\n",
        "\n",
        "data_train=torch.tensor(data_train)\n",
        "data_test=torch.tensor(data_test)\n",
        "targets_train=torch.tensor(targets_train)\n",
        "targets_test=torch.tensor(targets_test)\n",
        "#print(targets_test.shape[1])\n",
        "autoencoder = ELMAutoEncoder(data_train.shape[1], hidden_size,targets_test.shape[1])\n",
        "autoencoder.fit(data_train,targets_train, hidden_size)\n",
        "#print(data_train.shape)\n",
        "train_reconstruction_error,cos_dis = reconstruction_error(autoencoder,data_train,targets_train)\n",
        "# Calculate the mean squared error and cosine distance\n",
        "print('train mse error','{:.15f}'.format(train_reconstruction_error))\n",
        "print('train cosine distance','{:.15f}'.format(cos_dis))\n",
        "\n",
        "test_reconstruction_error,cos_dis = reconstruction_error(autoencoder,data_test,targets_test)\n",
        "print('test mse error',test_reconstruction_error)\n",
        "print('test cosine distance',cos_dis)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4fu_CG0LfQgs",
        "outputId": "9edfb72c-9d8c-4f0f-bb9b-3e1bf11317a5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-9a66e1d9b254>:114: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
            "  data_train=torch.tensor(data_train)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: CUDA not available, using CPU.\n",
            "output of hiddenlayer torch.Size([400, 500])\n",
            "output weight matrix torch.Size([500, 768])\n",
            "input to encoder torch.Size([400, 9216])\n",
            "encoded.shape torch.Size([400, 500])\n",
            "decoded torch.Size([400, 768])\n",
            "train mse error 0.000007786394220\n",
            "train cosine distance 0.403268322393927\n",
            "input to encoder torch.Size([100, 9216])\n",
            "encoded.shape torch.Size([100, 500])\n",
            "decoded torch.Size([100, 768])\n",
            "test mse error 0.00041739721020066125\n",
            "test cosine distance 0.4564410068879795\n"
          ]
        }
      ]
    }
  ]
}