{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install openai-clip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yozDushcUkhN",
        "outputId": "48c593c9-519f-4a7b-e5b5-83fec3e47aec"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m59.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m100.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.14.1 tokenizers-0.13.3 transformers-4.28.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai-clip\n",
            "  Downloading openai-clip-1.0.1.tar.gz (1.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting ftfy\n",
            "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from openai-clip) (2022.10.31)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-clip) (4.65.0)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.10/dist-packages (from ftfy->openai-clip) (0.2.6)\n",
            "Building wheels for collected packages: openai-clip\n",
            "  Building wheel for openai-clip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-clip: filename=openai_clip-1.0.1-py3-none-any.whl size=1368637 sha256=9450e159577e44733281064333f5c4f1ae4985e2d979c053af220319d218524d\n",
            "  Stored in directory: /root/.cache/pip/wheels/08/77/8e/8d2f862df6bf7fb4e2007062d2cbaeae49862ec7b56d041229\n",
            "Successfully built openai-clip\n",
            "Installing collected packages: ftfy, openai-clip\n",
            "Successfully installed ftfy-6.1.1 openai-clip-1.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQ1qSlaCSqBg",
        "outputId": "c23dea49-d9c5-4e6c-e981-49562b299079"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "wasteland 2d pixel art cave\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "phrase_list = ['2d', 'pixel art', 'cave', 'scifi', 'side scrolling', 'chibi', 'waifu', 'space ship', 'desert', 'city', 'wasteland', 'mega structure', 'steal', 'stone', 'rock']\n",
        "\n",
        "def prompt_generator(phrase_list, prompt_word_length=32):\n",
        "    prompt = ''\n",
        "    while len(prompt) < prompt_word_length:\n",
        "        phrase = random.choice(phrase_list)\n",
        "        if len(prompt) + len(phrase) + 1 <= prompt_word_length:\n",
        "            prompt += phrase + ' '\n",
        "        else:\n",
        "            break\n",
        "    return prompt.strip()\n",
        "\n",
        "# example usage:\n",
        "prompt=prompt_generator(phrase_list) \n",
        "print(prompt_generator(phrase_list))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u7Jht2TnpWDP",
        "outputId": "ece77709-a45a-4055-d121-e0023b7fdb88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "scifi mega structure rock cave\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import clip\n",
        "import numpy as np\n",
        "\n",
        "use_cuda = torch.cuda.is_available()\n",
        "if use_cuda:\n",
        "    # Move tensors to CUDA device\n",
        "    device = torch.device('cuda:0')\n",
        "    print(f\"Using CUDA device: {torch.cuda.get_device_name(device)}\")\n",
        "else:\n",
        "    # Use CPU\n",
        "    device = torch.device('cpu')\n",
        "    print(\"Warning: CUDA not available, using CPU.\")\n",
        "\n",
        "# Load the CLIP model\n",
        "model, preprocess = clip.load(\"ViT-L/14\", device=device)\n",
        "\n",
        "# Tokenize and encode the prompt\n",
        "prompt = \"scifi mega structure rock cave\"\n",
        "tokens = clip.tokenize(prompt).to(device)\n",
        "print(\"Size of tokens:\", tokens.shape)\n",
        "with torch.no_grad():\n",
        "    text_features = model.encode_text(tokens).float()\n",
        "    text_features /= text_features.norm(dim=-1, keepdim=True)\n",
        "\n",
        "# Convert the embedding to a numpy array\n",
        "embedding = text_features.cpu().numpy()\n",
        "\n",
        "print(\"Text embedding shape:\",embedding.shape)  # should print (1, 768)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-9eq9c0caIf",
        "outputId": "06bb8361-989c-4fe3-bd34-2d40b54504c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████████████| 890M/890M [00:15<00:00, 61.7MiB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of tokens: torch.Size([1, 77])\n",
            "Text embedding shape: (1, 768)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run for obtaining random prompts, word embeddings and clip embeddings"
      ],
      "metadata": {
        "id": "Uw78nDSvHaYY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import torch\n",
        "import clip\n",
        "import random\n",
        "import numpy as np\n",
        "from typing import List\n",
        "from torch import nn\n",
        "from transformers import CLIPTokenizer, CLIPTextModel\n",
        "\n",
        "phrase_list = ['2d', 'pixel art', 'cave', 'scifi', 'side scrolling', 'chibi', 'waifu', 'space ship', 'desert', 'city', 'wasteland', 'mega structure', 'steal', 'stone', 'rock']\n",
        "\n",
        "N=500\n",
        "\n",
        "# Load the CLIP model\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model, preprocess = clip.load(\"ViT-L/14\", device=device)\n",
        "\n",
        "\n",
        "\n",
        "class CLIPTextEmbedder(nn.Module):\n",
        "    \"\"\"\n",
        "    ## CLIP Text Embedder\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, version: str = \"openai/clip-vit-large-patch14\", device=\"cuda:0\", max_length: int = 12):\n",
        "        \"\"\"\n",
        "        :param version: is the model version\n",
        "        :param device: is the device\n",
        "        :param max_length: is the max length of the tokenized prompt\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        # Load the tokenizer\n",
        "        self.tokenizer = CLIPTokenizer.from_pretrained(version)\n",
        "        print(self.tokenizer)\n",
        "        # Load the CLIP transformer\n",
        "        self.transformer = CLIPTextModel.from_pretrained(version).eval()\n",
        "\n",
        "        #self.device = device\n",
        "        self.device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "  \n",
        "        self.max_length = max_length\n",
        "\n",
        "    def forward(self, prompts: List[str]):\n",
        "        \"\"\"\n",
        "        :param prompts: are the list of prompts to embed\n",
        "        \"\"\"\n",
        "        # Tokenize the prompts\n",
        "        batch_encoding = self.tokenizer(prompts, truncation=True, max_length=self.max_length, return_length=True,\n",
        "                                        return_overflowing_tokens=False, padding=\"max_length\", return_tensors=\"pt\")\n",
        "        # Get token ids\n",
        "        tokens = batch_encoding[\"input_ids\"].to(self.device)\n",
        "        # Get CLIP embeddings\n",
        "        return self.transformer(input_ids=tokens).last_hidden_state\n",
        "\n",
        "def generate_prompts(num_prompts, phrase_list, prompt_word_length,x):\n",
        "    prompts = []\n",
        "    for i in range(num_prompts):\n",
        "        # Generate prompt\n",
        "        prompt = ''\n",
        "        while len(prompt) < prompt_word_length:\n",
        "            phrase = random.choice(phrase_list)\n",
        "            if len(prompt) + len(phrase) + 1 <= prompt_word_length:\n",
        "                prompt += phrase + ' '\n",
        "            else:\n",
        "                break\n",
        "        prompt = prompt.strip()\n",
        "        \n",
        "        # Get word embedding\n",
        "        with torch.no_grad():\n",
        "            tokens = clip.tokenize(prompt).to(device)\n",
        "            print(tokens.shape)\n",
        "            print(tokens)\n",
        "            print(type(tokens))\n",
        "            out = x.forward(prompt)\n",
        "            out=torch.flatten(out)\n",
        "            out=torch.unsqueeze(out,0)\n",
        "            print(out)\n",
        "            print(type(out))\n",
        "            print(out.shape)\n",
        "        #    text_features = model.encode_text(tokens).float()\n",
        "            print('Computing text embedding for Prompt'+str(i+1))\n",
        "            text_features = model.encode_text(tokens).float()\n",
        "            text_features /= text_features.norm(dim=-1, keepdim=True)\n",
        "            print(text_features.shape)\n",
        "            prompt_data = {\n",
        "            \"prompt\": prompt,\n",
        "            \"word_embedding\": out[0].tolist(),\n",
        "            \"clip_embedding\": text_features[0].tolist(),\n",
        "        }\n",
        "\n",
        "        # Append prompt, word embedding, and clip embedding to list\n",
        "        prompts.append(prompt_data)    \n",
        "    # Save prompts as JSON to file\n",
        "    with open(\"prompts_and_embeddings.json\", \"w\") as f:\n",
        "      json.dump(prompts, f)\n",
        "\n",
        "x = CLIPTextEmbedder()\n",
        "prompt_word_length=32\n",
        "generate_prompts(N, phrase_list,prompt_word_length,x)\n",
        "print('Process completed and dataset is generated')"
      ],
      "metadata": {
        "id": "9WBWA1-dim2-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85f44a08-3479-49b3-db87-b7f82e47c840"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CLIPTokenizer(name_or_path='openai/clip-vit-large-patch14', vocab_size=49408, model_max_length=77, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': AddedToken(\"<|startoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'eos_token': AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'unk_token': AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'pad_token': '<|endoftext|>'}, clean_up_tokenization_spaces=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at openai/clip-vit-large-patch14 were not used when initializing CLIPTextModel: ['vision_model.encoder.layers.4.self_attn.q_proj.bias', 'vision_model.encoder.layers.0.self_attn.q_proj.weight', 'vision_model.encoder.layers.9.self_attn.v_proj.bias', 'vision_model.encoder.layers.19.self_attn.q_proj.weight', 'vision_model.encoder.layers.23.self_attn.v_proj.bias', 'vision_model.encoder.layers.17.layer_norm2.bias', 'vision_model.encoder.layers.6.self_attn.out_proj.bias', 'vision_model.encoder.layers.19.self_attn.q_proj.bias', 'vision_model.encoder.layers.21.self_attn.q_proj.weight', 'vision_model.encoder.layers.3.layer_norm2.bias', 'vision_model.encoder.layers.20.mlp.fc2.weight', 'vision_model.encoder.layers.12.layer_norm2.bias', 'vision_model.encoder.layers.17.self_attn.k_proj.bias', 'vision_model.encoder.layers.12.layer_norm1.weight', 'vision_model.embeddings.position_embedding.weight', 'vision_model.encoder.layers.23.mlp.fc2.bias', 'vision_model.encoder.layers.14.layer_norm2.bias', 'vision_model.encoder.layers.22.layer_norm2.weight', 'vision_model.encoder.layers.17.mlp.fc1.bias', 'vision_model.encoder.layers.19.self_attn.v_proj.weight', 'vision_model.encoder.layers.0.mlp.fc2.weight', 'vision_model.encoder.layers.10.self_attn.q_proj.bias', 'vision_model.encoder.layers.14.self_attn.out_proj.bias', 'vision_model.encoder.layers.20.self_attn.k_proj.bias', 'vision_model.encoder.layers.21.self_attn.q_proj.bias', 'vision_model.encoder.layers.16.layer_norm1.bias', 'vision_model.encoder.layers.10.self_attn.v_proj.bias', 'vision_model.encoder.layers.0.self_attn.k_proj.weight', 'vision_model.encoder.layers.16.self_attn.k_proj.bias', 'vision_model.encoder.layers.10.self_attn.q_proj.weight', 'vision_model.encoder.layers.23.layer_norm2.bias', 'vision_model.encoder.layers.15.layer_norm2.bias', 'vision_model.encoder.layers.16.self_attn.k_proj.weight', 'vision_model.encoder.layers.7.layer_norm2.weight', 'vision_model.encoder.layers.18.self_attn.k_proj.bias', 'vision_model.encoder.layers.22.self_attn.q_proj.bias', 'vision_model.encoder.layers.13.layer_norm2.weight', 'vision_model.encoder.layers.14.layer_norm2.weight', 'vision_model.encoder.layers.21.layer_norm2.weight', 'vision_model.encoder.layers.17.mlp.fc2.bias', 'vision_model.encoder.layers.12.mlp.fc1.weight', 'vision_model.encoder.layers.20.self_attn.v_proj.weight', 'vision_model.encoder.layers.7.self_attn.v_proj.weight', 'vision_model.encoder.layers.3.mlp.fc2.bias', 'vision_model.encoder.layers.3.mlp.fc1.bias', 'vision_model.encoder.layers.10.layer_norm2.weight', 'vision_model.encoder.layers.16.layer_norm2.bias', 'vision_model.encoder.layers.16.layer_norm2.weight', 'vision_model.encoder.layers.2.mlp.fc2.weight', 'vision_model.encoder.layers.0.self_attn.out_proj.bias', 'vision_model.encoder.layers.15.self_attn.q_proj.weight', 'vision_model.encoder.layers.19.mlp.fc1.weight', 'vision_model.encoder.layers.14.mlp.fc2.weight', 'vision_model.encoder.layers.22.mlp.fc1.weight', 'vision_model.encoder.layers.16.mlp.fc2.weight', 'vision_model.encoder.layers.15.layer_norm1.weight', 'vision_model.embeddings.position_ids', 'vision_model.encoder.layers.4.layer_norm2.bias', 'vision_model.encoder.layers.21.self_attn.v_proj.bias', 'vision_model.encoder.layers.13.self_attn.out_proj.weight', 'vision_model.encoder.layers.6.layer_norm2.weight', 'vision_model.encoder.layers.19.layer_norm2.weight', 'vision_model.encoder.layers.3.layer_norm1.weight', 'vision_model.encoder.layers.7.self_attn.v_proj.bias', 'vision_model.encoder.layers.8.layer_norm1.weight', 'vision_model.encoder.layers.0.mlp.fc1.weight', 'vision_model.encoder.layers.10.layer_norm1.bias', 'vision_model.encoder.layers.23.layer_norm1.bias', 'vision_model.encoder.layers.1.self_attn.q_proj.bias', 'vision_model.encoder.layers.8.mlp.fc2.weight', 'vision_model.encoder.layers.17.layer_norm1.weight', 'vision_model.encoder.layers.12.self_attn.out_proj.bias', 'vision_model.encoder.layers.20.layer_norm1.weight', 'vision_model.encoder.layers.14.layer_norm1.weight', 'vision_model.encoder.layers.20.layer_norm2.weight', 'vision_model.encoder.layers.2.mlp.fc1.weight', 'vision_model.encoder.layers.5.self_attn.v_proj.weight', 'vision_model.encoder.layers.15.mlp.fc1.bias', 'vision_model.encoder.layers.1.mlp.fc1.weight', 'vision_model.encoder.layers.14.self_attn.k_proj.bias', 'vision_model.encoder.layers.21.layer_norm2.bias', 'vision_model.encoder.layers.11.self_attn.k_proj.weight', 'vision_model.encoder.layers.9.mlp.fc1.bias', 'vision_model.encoder.layers.22.layer_norm1.bias', 'vision_model.encoder.layers.22.layer_norm1.weight', 'vision_model.encoder.layers.18.self_attn.v_proj.weight', 'vision_model.encoder.layers.15.mlp.fc2.bias', 'vision_model.encoder.layers.13.self_attn.k_proj.weight', 'vision_model.encoder.layers.1.self_attn.k_proj.bias', 'vision_model.encoder.layers.21.layer_norm1.weight', 'vision_model.encoder.layers.4.layer_norm1.bias', 'vision_model.encoder.layers.19.layer_norm2.bias', 'vision_model.encoder.layers.5.self_attn.q_proj.bias', 'vision_model.encoder.layers.20.self_attn.v_proj.bias', 'vision_model.encoder.layers.1.self_attn.q_proj.weight', 'vision_model.encoder.layers.12.mlp.fc1.bias', 'vision_model.encoder.layers.23.layer_norm1.weight', 'vision_model.encoder.layers.1.self_attn.out_proj.bias', 'vision_model.encoder.layers.21.layer_norm1.bias', 'vision_model.encoder.layers.8.self_attn.k_proj.weight', 'vision_model.encoder.layers.6.self_attn.v_proj.bias', 'vision_model.encoder.layers.19.mlp.fc1.bias', 'vision_model.encoder.layers.20.self_attn.out_proj.weight', 'vision_model.encoder.layers.4.mlp.fc2.weight', 'vision_model.encoder.layers.7.self_attn.q_proj.bias', 'vision_model.encoder.layers.15.mlp.fc1.weight', 'vision_model.encoder.layers.5.layer_norm1.weight', 'vision_model.encoder.layers.12.layer_norm1.bias', 'vision_model.encoder.layers.11.layer_norm1.weight', 'vision_model.encoder.layers.11.mlp.fc2.bias', 'vision_model.encoder.layers.22.layer_norm2.bias', 'vision_model.encoder.layers.3.self_attn.k_proj.bias', 'vision_model.encoder.layers.2.self_attn.v_proj.bias', 'vision_model.encoder.layers.11.self_attn.v_proj.weight', 'vision_model.encoder.layers.21.mlp.fc2.bias', 'vision_model.encoder.layers.5.mlp.fc2.bias', 'vision_model.encoder.layers.1.layer_norm1.weight', 'vision_model.encoder.layers.18.layer_norm1.weight', 'vision_model.pre_layrnorm.weight', 'vision_model.encoder.layers.22.self_attn.k_proj.bias', 'vision_model.encoder.layers.16.self_attn.v_proj.weight', 'vision_model.encoder.layers.8.self_attn.k_proj.bias', 'vision_model.encoder.layers.2.mlp.fc2.bias', 'vision_model.encoder.layers.5.layer_norm1.bias', 'vision_model.encoder.layers.17.self_attn.out_proj.weight', 'vision_model.encoder.layers.22.self_attn.q_proj.weight', 'vision_model.encoder.layers.10.self_attn.k_proj.weight', 'vision_model.encoder.layers.19.mlp.fc2.bias', 'vision_model.encoder.layers.22.mlp.fc2.bias', 'vision_model.encoder.layers.1.layer_norm2.bias', 'vision_model.encoder.layers.1.self_attn.k_proj.weight', 'vision_model.encoder.layers.7.self_attn.k_proj.weight', 'vision_model.encoder.layers.10.self_attn.k_proj.bias', 'vision_model.encoder.layers.20.self_attn.out_proj.bias', 'vision_model.encoder.layers.15.self_attn.k_proj.bias', 'vision_model.encoder.layers.16.layer_norm1.weight', 'vision_model.encoder.layers.23.self_attn.v_proj.weight', 'vision_model.encoder.layers.0.self_attn.v_proj.weight', 'vision_model.encoder.layers.10.layer_norm2.bias', 'vision_model.encoder.layers.3.layer_norm1.bias', 'vision_model.encoder.layers.13.self_attn.q_proj.bias', 'vision_model.encoder.layers.14.self_attn.out_proj.weight', 'vision_model.encoder.layers.17.layer_norm1.bias', 'vision_model.encoder.layers.0.self_attn.v_proj.bias', 'vision_model.encoder.layers.4.self_attn.k_proj.bias', 'vision_model.encoder.layers.17.self_attn.k_proj.weight', 'vision_model.encoder.layers.6.mlp.fc2.bias', 'vision_model.encoder.layers.1.mlp.fc2.bias', 'vision_model.encoder.layers.4.layer_norm1.weight', 'vision_model.encoder.layers.1.self_attn.v_proj.bias', 'vision_model.encoder.layers.11.mlp.fc2.weight', 'vision_model.encoder.layers.8.mlp.fc1.bias', 'vision_model.encoder.layers.14.mlp.fc1.bias', 'vision_model.encoder.layers.13.self_attn.out_proj.bias', 'vision_model.encoder.layers.19.self_attn.out_proj.weight', 'logit_scale', 'vision_model.encoder.layers.2.self_attn.k_proj.bias', 'vision_model.encoder.layers.16.mlp.fc1.weight', 'vision_model.encoder.layers.5.self_attn.k_proj.bias', 'vision_model.encoder.layers.14.self_attn.v_proj.weight', 'vision_model.encoder.layers.7.mlp.fc2.bias', 'vision_model.encoder.layers.23.self_attn.q_proj.bias', 'vision_model.encoder.layers.9.layer_norm2.bias', 'vision_model.encoder.layers.23.self_attn.out_proj.weight', 'vision_model.encoder.layers.6.self_attn.q_proj.weight', 'vision_model.encoder.layers.10.layer_norm1.weight', 'vision_model.encoder.layers.4.self_attn.q_proj.weight', 'vision_model.encoder.layers.17.self_attn.out_proj.bias', 'vision_model.encoder.layers.14.self_attn.v_proj.bias', 'vision_model.encoder.layers.9.layer_norm1.bias', 'vision_model.encoder.layers.3.self_attn.out_proj.weight', 'vision_model.encoder.layers.23.layer_norm2.weight', 'vision_model.encoder.layers.6.mlp.fc1.bias', 'vision_model.encoder.layers.13.self_attn.q_proj.weight', 'vision_model.encoder.layers.8.layer_norm2.weight', 'vision_model.encoder.layers.0.layer_norm2.weight', 'vision_model.encoder.layers.0.layer_norm1.bias', 'vision_model.encoder.layers.21.self_attn.k_proj.bias', 'vision_model.encoder.layers.10.mlp.fc1.bias', 'vision_model.encoder.layers.18.mlp.fc1.bias', 'vision_model.encoder.layers.21.self_attn.out_proj.bias', 'vision_model.encoder.layers.16.self_attn.q_proj.weight', 'vision_model.encoder.layers.23.self_attn.out_proj.bias', 'vision_model.pre_layrnorm.bias', 'vision_model.encoder.layers.3.self_attn.k_proj.weight', 'vision_model.encoder.layers.18.mlp.fc2.bias', 'vision_model.encoder.layers.7.self_attn.q_proj.weight', 'vision_model.encoder.layers.19.self_attn.v_proj.bias', 'vision_model.encoder.layers.8.self_attn.out_proj.weight', 'vision_model.encoder.layers.22.self_attn.k_proj.weight', 'vision_model.encoder.layers.10.mlp.fc1.weight', 'vision_model.encoder.layers.13.mlp.fc2.bias', 'vision_model.encoder.layers.10.mlp.fc2.bias', 'vision_model.encoder.layers.9.self_attn.q_proj.bias', 'vision_model.encoder.layers.15.layer_norm2.weight', 'vision_model.encoder.layers.5.self_attn.k_proj.weight', 'vision_model.encoder.layers.5.self_attn.v_proj.bias', 'vision_model.encoder.layers.1.layer_norm1.bias', 'vision_model.encoder.layers.13.mlp.fc2.weight', 'vision_model.encoder.layers.13.self_attn.v_proj.bias', 'vision_model.encoder.layers.20.self_attn.q_proj.bias', 'vision_model.encoder.layers.3.self_attn.q_proj.bias', 'vision_model.encoder.layers.6.self_attn.k_proj.weight', 'vision_model.encoder.layers.5.self_attn.q_proj.weight', 'vision_model.encoder.layers.18.self_attn.out_proj.weight', 'vision_model.encoder.layers.22.mlp.fc2.weight', 'vision_model.encoder.layers.3.self_attn.q_proj.weight', 'vision_model.encoder.layers.12.self_attn.v_proj.weight', 'vision_model.encoder.layers.18.layer_norm1.bias', 'vision_model.encoder.layers.17.mlp.fc1.weight', 'vision_model.encoder.layers.20.mlp.fc1.bias', 'vision_model.encoder.layers.8.self_attn.out_proj.bias', 'vision_model.encoder.layers.11.layer_norm2.bias', 'vision_model.encoder.layers.20.self_attn.q_proj.weight', 'vision_model.encoder.layers.23.mlp.fc1.bias', 'vision_model.encoder.layers.12.mlp.fc2.weight', 'vision_model.encoder.layers.18.mlp.fc1.weight', 'vision_model.encoder.layers.23.mlp.fc2.weight', 'vision_model.encoder.layers.10.self_attn.out_proj.weight', 'vision_model.post_layernorm.weight', 'vision_model.encoder.layers.12.self_attn.out_proj.weight', 'vision_model.encoder.layers.7.self_attn.out_proj.weight', 'vision_model.encoder.layers.23.self_attn.k_proj.bias', 'vision_model.encoder.layers.17.layer_norm2.weight', 'vision_model.encoder.layers.14.self_attn.k_proj.weight', 'vision_model.encoder.layers.5.layer_norm2.weight', 'vision_model.encoder.layers.8.self_attn.q_proj.bias', 'vision_model.encoder.layers.11.self_attn.v_proj.bias', 'vision_model.encoder.layers.11.self_attn.out_proj.bias', 'vision_model.encoder.layers.15.layer_norm1.bias', 'vision_model.encoder.layers.10.self_attn.v_proj.weight', 'visual_projection.weight', 'vision_model.encoder.layers.23.mlp.fc1.weight', 'vision_model.encoder.layers.19.layer_norm1.bias', 'vision_model.encoder.layers.15.self_attn.v_proj.bias', 'vision_model.encoder.layers.13.layer_norm1.weight', 'vision_model.encoder.layers.4.mlp.fc1.bias', 'vision_model.encoder.layers.18.layer_norm2.bias', 'vision_model.encoder.layers.13.layer_norm1.bias', 'vision_model.encoder.layers.2.layer_norm1.bias', 'vision_model.encoder.layers.22.self_attn.out_proj.bias', 'vision_model.encoder.layers.8.mlp.fc2.bias', 'vision_model.encoder.layers.3.self_attn.v_proj.weight', 'vision_model.encoder.layers.18.layer_norm2.weight', 'vision_model.encoder.layers.9.mlp.fc1.weight', 'vision_model.encoder.layers.5.mlp.fc2.weight', 'vision_model.encoder.layers.4.mlp.fc2.bias', 'vision_model.encoder.layers.18.mlp.fc2.weight', 'vision_model.encoder.layers.2.self_attn.out_proj.bias', 'vision_model.encoder.layers.15.mlp.fc2.weight', 'vision_model.encoder.layers.6.layer_norm1.bias', 'vision_model.encoder.layers.4.self_attn.out_proj.bias', 'vision_model.encoder.layers.17.self_attn.v_proj.bias', 'vision_model.encoder.layers.3.mlp.fc2.weight', 'vision_model.encoder.layers.21.mlp.fc1.bias', 'vision_model.encoder.layers.21.self_attn.k_proj.weight', 'vision_model.encoder.layers.12.self_attn.v_proj.bias', 'vision_model.encoder.layers.0.mlp.fc2.bias', 'vision_model.encoder.layers.5.layer_norm2.bias', 'vision_model.encoder.layers.1.mlp.fc1.bias', 'vision_model.encoder.layers.19.mlp.fc2.weight', 'vision_model.encoder.layers.8.layer_norm1.bias', 'vision_model.encoder.layers.13.mlp.fc1.weight', 'vision_model.encoder.layers.15.self_attn.v_proj.weight', 'vision_model.encoder.layers.7.layer_norm1.bias', 'vision_model.encoder.layers.5.self_attn.out_proj.bias', 'vision_model.encoder.layers.15.self_attn.q_proj.bias', 'vision_model.encoder.layers.21.self_attn.out_proj.weight', 'vision_model.encoder.layers.11.self_attn.k_proj.bias', 'vision_model.encoder.layers.10.self_attn.out_proj.bias', 'vision_model.encoder.layers.2.mlp.fc1.bias', 'vision_model.encoder.layers.9.self_attn.out_proj.bias', 'vision_model.encoder.layers.16.mlp.fc1.bias', 'vision_model.encoder.layers.2.layer_norm2.bias', 'vision_model.encoder.layers.5.self_attn.out_proj.weight', 'vision_model.encoder.layers.9.mlp.fc2.bias', 'vision_model.encoder.layers.12.mlp.fc2.bias', 'vision_model.encoder.layers.1.self_attn.v_proj.weight', 'vision_model.encoder.layers.8.self_attn.v_proj.weight', 'vision_model.encoder.layers.13.self_attn.k_proj.bias', 'vision_model.encoder.layers.8.self_attn.v_proj.bias', 'vision_model.encoder.layers.23.self_attn.k_proj.weight', 'vision_model.encoder.layers.6.mlp.fc1.weight', 'vision_model.encoder.layers.9.self_attn.q_proj.weight', 'vision_model.encoder.layers.14.mlp.fc1.weight', 'vision_model.encoder.layers.7.mlp.fc1.weight', 'vision_model.encoder.layers.9.layer_norm2.weight', 'vision_model.encoder.layers.12.self_attn.q_proj.bias', 'vision_model.encoder.layers.17.self_attn.q_proj.weight', 'vision_model.encoder.layers.8.self_attn.q_proj.weight', 'vision_model.encoder.layers.12.self_attn.k_proj.bias', 'vision_model.encoder.layers.9.self_attn.out_proj.weight', 'vision_model.encoder.layers.3.mlp.fc1.weight', 'vision_model.encoder.layers.0.self_attn.out_proj.weight', 'vision_model.encoder.layers.5.mlp.fc1.weight', 'vision_model.encoder.layers.1.layer_norm2.weight', 'vision_model.encoder.layers.12.self_attn.q_proj.weight', 'vision_model.encoder.layers.7.mlp.fc1.bias', 'vision_model.encoder.layers.0.layer_norm2.bias', 'vision_model.encoder.layers.2.self_attn.k_proj.weight', 'vision_model.encoder.layers.8.mlp.fc1.weight', 'vision_model.encoder.layers.12.self_attn.k_proj.weight', 'vision_model.encoder.layers.19.layer_norm1.weight', 'vision_model.encoder.layers.22.self_attn.out_proj.weight', 'vision_model.encoder.layers.6.layer_norm2.bias', 'vision_model.encoder.layers.14.mlp.fc2.bias', 'text_projection.weight', 'vision_model.encoder.layers.4.self_attn.v_proj.weight', 'vision_model.encoder.layers.6.mlp.fc2.weight', 'vision_model.encoder.layers.17.self_attn.v_proj.weight', 'vision_model.encoder.layers.0.mlp.fc1.bias', 'vision_model.encoder.layers.6.self_attn.k_proj.bias', 'vision_model.encoder.layers.18.self_attn.q_proj.bias', 'vision_model.encoder.layers.11.self_attn.out_proj.weight', 'vision_model.encoder.layers.6.layer_norm1.weight', 'vision_model.encoder.layers.17.self_attn.q_proj.bias', 'vision_model.encoder.layers.2.layer_norm2.weight', 'vision_model.encoder.layers.6.self_attn.q_proj.bias', 'vision_model.encoder.layers.14.self_attn.q_proj.bias', 'vision_model.encoder.layers.21.self_attn.v_proj.weight', 'vision_model.encoder.layers.0.layer_norm1.weight', 'vision_model.encoder.layers.23.self_attn.q_proj.weight', 'vision_model.encoder.layers.8.layer_norm2.bias', 'vision_model.encoder.layers.16.self_attn.out_proj.bias', 'vision_model.encoder.layers.11.self_attn.q_proj.bias', 'vision_model.encoder.layers.2.self_attn.q_proj.bias', 'vision_model.encoder.layers.4.self_attn.out_proj.weight', 'vision_model.encoder.layers.15.self_attn.out_proj.bias', 'vision_model.encoder.layers.21.mlp.fc1.weight', 'vision_model.encoder.layers.16.self_attn.out_proj.weight', 'vision_model.encoder.layers.3.self_attn.v_proj.bias', 'vision_model.encoder.layers.12.layer_norm2.weight', 'vision_model.encoder.layers.18.self_attn.out_proj.bias', 'vision_model.encoder.layers.2.self_attn.q_proj.weight', 'vision_model.encoder.layers.13.self_attn.v_proj.weight', 'vision_model.encoder.layers.20.mlp.fc1.weight', 'vision_model.encoder.layers.7.self_attn.k_proj.bias', 'vision_model.encoder.layers.7.mlp.fc2.weight', 'vision_model.encoder.layers.20.layer_norm2.bias', 'vision_model.encoder.layers.4.layer_norm2.weight', 'vision_model.encoder.layers.4.self_attn.v_proj.bias', 'vision_model.encoder.layers.18.self_attn.q_proj.weight', 'vision_model.encoder.layers.0.self_attn.k_proj.bias', 'vision_model.encoder.layers.6.self_attn.v_proj.weight', 'vision_model.encoder.layers.22.self_attn.v_proj.weight', 'vision_model.encoder.layers.9.mlp.fc2.weight', 'vision_model.encoder.layers.2.layer_norm1.weight', 'vision_model.embeddings.class_embedding', 'vision_model.encoder.layers.1.mlp.fc2.weight', 'vision_model.encoder.layers.22.self_attn.v_proj.bias', 'vision_model.encoder.layers.4.mlp.fc1.weight', 'vision_model.encoder.layers.14.layer_norm1.bias', 'vision_model.encoder.layers.15.self_attn.out_proj.weight', 'vision_model.encoder.layers.11.layer_norm1.bias', 'vision_model.post_layernorm.bias', 'vision_model.encoder.layers.11.layer_norm2.weight', 'vision_model.encoder.layers.18.self_attn.k_proj.weight', 'vision_model.encoder.layers.21.mlp.fc2.weight', 'vision_model.encoder.layers.3.self_attn.out_proj.bias', 'vision_model.encoder.layers.11.self_attn.q_proj.weight', 'vision_model.encoder.layers.11.mlp.fc1.bias', 'vision_model.encoder.layers.1.self_attn.out_proj.weight', 'vision_model.encoder.layers.2.self_attn.v_proj.weight', 'vision_model.encoder.layers.19.self_attn.k_proj.weight', 'vision_model.encoder.layers.9.self_attn.k_proj.weight', 'vision_model.encoder.layers.16.mlp.fc2.bias', 'vision_model.encoder.layers.19.self_attn.out_proj.bias', 'vision_model.encoder.layers.16.self_attn.q_proj.bias', 'vision_model.encoder.layers.14.self_attn.q_proj.weight', 'vision_model.encoder.layers.13.mlp.fc1.bias', 'vision_model.encoder.layers.7.self_attn.out_proj.bias', 'vision_model.encoder.layers.0.self_attn.q_proj.bias', 'vision_model.encoder.layers.19.self_attn.k_proj.bias', 'vision_model.encoder.layers.20.layer_norm1.bias', 'vision_model.encoder.layers.17.mlp.fc2.weight', 'vision_model.encoder.layers.20.self_attn.k_proj.weight', 'vision_model.encoder.layers.10.mlp.fc2.weight', 'vision_model.encoder.layers.6.self_attn.out_proj.weight', 'vision_model.encoder.layers.15.self_attn.k_proj.weight', 'vision_model.encoder.layers.4.self_attn.k_proj.weight', 'vision_model.encoder.layers.11.mlp.fc1.weight', 'vision_model.encoder.layers.13.layer_norm2.bias', 'vision_model.encoder.layers.7.layer_norm1.weight', 'vision_model.encoder.layers.5.mlp.fc1.bias', 'vision_model.encoder.layers.2.self_attn.out_proj.weight', 'vision_model.encoder.layers.18.self_attn.v_proj.bias', 'vision_model.encoder.layers.9.layer_norm1.weight', 'vision_model.encoder.layers.9.self_attn.v_proj.weight', 'vision_model.encoder.layers.22.mlp.fc1.bias', 'vision_model.embeddings.patch_embedding.weight', 'vision_model.encoder.layers.9.self_attn.k_proj.bias', 'vision_model.encoder.layers.7.layer_norm2.bias', 'vision_model.encoder.layers.3.layer_norm2.weight', 'vision_model.encoder.layers.20.mlp.fc2.bias', 'vision_model.encoder.layers.16.self_attn.v_proj.bias']\n",
            "- This IS expected if you are initializing CLIPTextModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing CLIPTextModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt167\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 12230,  9068,  5285, 12230, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.3065, -0.7406, -0.0718]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt168\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  9654,  9068,  5285, 44035, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.4230, -0.3582,  0.1260]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt169\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 13241,   794,  2172,  9654,  2172, 22306, 49407,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.5670,  0.6776, -1.2416]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt170\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2441,  1305,  1145, 28889,  9654, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.9600,  0.6911, -0.6338]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt171\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 10181, 46551,  2441, 22306,  9654, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.6274,  0.1958, -1.3621]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt172\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  1145, 28889, 13241,   794,  2172, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.6805, -0.2740, -0.5679]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt173\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 46551,  1305,   273,   323, 44035, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ...,  0.0217, -0.8798, -1.2767]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt174\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 13241,   794, 10181, 22306, 22306, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.3200,  0.5470, -1.4475]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt175\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  1305,  1145, 28889,  2138,  1158, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.5535,  0.1518, -0.5080]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt176\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 13241,   794, 12230,  2138,  1158, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.5514, -0.4182, -0.8325]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt177\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  9068,  5285, 22306, 44035, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.4315, -0.3900, -0.7721]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt178\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  1305,  2441,  2441,   273,   323, 13241,   794, 49407,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.5377,  0.0254, -1.3074]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt179\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  1145, 28889,   273,   323, 12230,  2172, 49407,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.5948, -0.7462, -0.4988]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt180\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 44035, 22306,   273,   323, 44035, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.8113, -0.4667, -1.8048]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt181\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 12230, 13241,   794,  2441, 12230, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.7788,  0.3763, -1.5531]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt182\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 22306, 13241,   794, 22306,  1305, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.4121,  0.0783, -1.1410]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt183\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,   273,   323,  9068,  5285,  1305, 10181, 49407,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.0417, -0.0685, -0.0638]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt184\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  1145, 28889,  2172,  1305, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.5000, -0.7516, -0.7053]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt185\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 46551,  1145, 28889, 13241,   794, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.4493, -0.1541, -0.8334]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt186\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 13241,   794,  2441,  2172,  1305, 12230, 49407,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.7810, -0.3944, -0.9891]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt187\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 10181,  7301, 22306, 13241,   794, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.7102,  0.3994, -1.4435]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt188\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2172, 13241,   794,  9654,  9654, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.3800,  0.2929, -0.6623]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt189\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 46551, 46551,  2172,  2138,  1158, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.3038, -0.0774, -0.6463]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt190\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  9654,   273,   323, 10181, 10181, 10181, 22306, 49407,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.6370, -0.1657, -1.5731]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt191\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2172,  2441,   273,   323,  2138,  1158,  9654, 49407,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.3374, -0.0626, -1.2855]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt192\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2441,  9654,  9654,  9654, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.3313,  0.7976, -0.0081]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt193\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  1145, 28889,  2138,  1158, 12230, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.7913, -0.2974, -0.4056]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt194\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  9068,  5285,  9068,  5285, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.0266, -0.6639,  1.0066]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt195\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  9654, 44035,  1305, 46551, 12230, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ...,  0.7084, -0.1407, -0.7324]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt196\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2441,  9654,  1305, 22306,  9654, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ...,  0.0851,  0.7381, -0.5605]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt197\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2172, 13241,   794, 12230,  9654, 22306, 49407,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.8366,  0.0707, -1.5395]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt198\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  1305, 12230,   273,   323,  9068,  5285, 49407,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ...,  0.5189, -1.1382, -0.3468]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt199\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 44035,  1305, 10181,  1305,  2441, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.3973,  0.2256, -0.2767]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt200\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,   273,   323, 12230,  7301, 12230, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.2815, -1.1888, -0.4946]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt201\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2441, 12230,  2172, 10181, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.7377,  0.9969, -0.5796]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt202\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 46551, 44035,  2138,  1158,  9654, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.2042, -0.2260, -1.3754]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt203\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 13241,   794, 12230,  1305, 13241,   794, 49407,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.6680, -0.0567, -0.4577]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt204\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  1305,  2441,  1145, 28889,  9654, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.7102,  1.3325, -0.9698]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt205\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2441,  7301, 46551,  1305, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.3992,  0.1866, -0.0181]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt206\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 44035,  2441, 22306,   273,   323, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.1546,  0.2715, -1.7183]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt207\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 44035,  2172, 46551,  2172, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.9971, -0.8946, -0.3380]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt208\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  9068,  5285,  9068,  5285, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.0266, -0.6639,  1.0066]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt209\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  1145, 28889,  7301, 22306, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.0282, -0.1013, -0.5041]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt210\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 12230,   273,   323,  1305, 22306, 44035, 49407,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.1317, -0.9169, -1.2805]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt211\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 12230, 10181, 46551,  9654,  2172, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.1356,  0.0423, -1.2721]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt212\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 46551,  1145, 28889,  2441,   273,   323, 49407,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.3409, -1.0489, -1.0914]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt213\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  9654,  1145, 28889,  2172, 10181, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.8914,  0.1255, -1.4055]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt214\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 10181,  2441,  2138,  1158,  7301, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.8776,  0.4934,  0.3442]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt215\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 12230,  2441, 46551, 49407,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ...,  1.1711, -0.3152, -1.5292]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt216\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2172,  1145, 28889,  2172,  2441, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.2330,  0.1106, -1.1011]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt217\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 44035, 10181,  9068,  5285, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.9034, -0.5010,  0.5008]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt218\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 10181,  9068,  5285,  7301, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.9809, -0.8392,  0.7419]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt219\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  9654,  7301, 10181,  1305,  7301, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.3883,  0.7061, -0.0259]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt220\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  9654,   273,   323,  9068,  5285, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ...,  0.5442, -1.3204,  0.1990]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt221\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  1145, 28889, 10181,   273,   323,   273,   323,  9654, 49407,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.1419, -0.1329, -1.0096]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt222\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 10181,  2138,  1158,  2172, 46551, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.7990, -0.2564, -0.4401]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt223\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  1145, 28889,  2172, 49407,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.3135, -0.6194, -0.5252]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt224\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2138,  1158, 12230,  1145, 28889, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.0258, -0.2767, -0.2050]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt225\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 13241,   794, 13241,   794, 46551,  2441, 49407,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ...,  0.2401, -0.1031, -1.5660]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt226\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 46551,  2172, 10181,  9654, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.1355,  0.0271, -0.7123]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt227\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 10181, 13241,   794, 44035,  2441, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.9397,  0.7608, -1.1955]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt228\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 12230,   273,   323, 12230,  1145, 28889, 49407,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.1375, -0.6252, -0.5268]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt229\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  1145, 28889, 22306,  1305, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.3885,  0.1780, -0.8908]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt230\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  9068,  5285,  9068,  5285, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.0266, -0.6639,  1.0066]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt231\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  9068,  5285, 22306, 13241,   794, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ...,  0.6674,  0.1226, -1.1608]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt232\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  7301, 13241,   794,  2441,  2441, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.1527,  0.1044, -1.2104]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt233\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2441,  2441,  2441, 13241,   794, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.8488,  0.4799, -0.8409]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt234\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 44035,  2172, 46551,  2138,  1158, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.6789, -0.1861, -0.6144]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt235\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  9068,  5285, 22306,  7301, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.3814, -0.3230, -0.4479]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt236\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  9654, 22306,  1145, 28889,  2172, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.1113,  0.3067, -1.2272]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt237\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2441,  9068,  5285, 49407,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ...,  0.0414, -0.2920,  0.2397]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt238\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  9068,  5285,  9654,  2172, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.4858,  0.3011,  0.3477]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt239\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2138,  1158,  7301, 46551, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.9934, -0.7276,  0.2181]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt240\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,   273,   323,  2138,  1158, 22306, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.0598, -0.1013, -1.8476]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt241\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  7301, 13241,   794, 10181,  7301, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.5916,  0.1077, -0.2127]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt242\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,   273,   323,  1305, 10181,  7301, 13241,   794, 49407,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.4219, -0.5649, -0.3840]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt243\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2172, 10181,  9068,  5285, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.7794, -0.2290,  0.0027]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt244\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 44035,  9068,  5285, 22306, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.3600, -0.0282, -0.4389]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt245\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2172,  2172,  2138,  1158,  9654, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.8165,  0.1060, -0.0289]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt246\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  1305,  2138,  1158, 12230, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.3326,  0.2212, -0.3038]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt247\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,   273,   323,  2172, 12230,  9654, 44035, 49407,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.4320, -1.1159, -1.1775]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt248\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 13241,   794,  9068,  5285,  1305, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.7519, -0.1652, -0.1327]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt249\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 22306,  1145, 28889, 49407,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.8291,  0.2942, -0.9688]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt250\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 46551,  2138,  1158,  2172, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.6917,  0.0763, -0.2763]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt251\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  9068,  5285, 46551,  1305,   273,   323, 49407,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ...,  0.1151, -1.1651, -0.9450]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt252\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 22306,  2138,  1158, 13241,   794,  2172, 49407,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.9671, -0.1574, -0.8801]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt253\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  7301,  9068,  5285,  7301, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.5991, -0.4718,  0.9506]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt254\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,   273,   323,  7301, 10181,  1305, 12230,  9654, 49407,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.6451, -0.6236, -0.4818]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt255\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 22306,  2138,  1158, 10181, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.5209,  1.1771, -1.1706]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt256\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 10181,  9654,  7301,  2441, 46551, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.6922, -0.2080, -0.8403]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt257\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  9068,  5285,  9068,  5285, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.0266, -0.6639,  1.0066]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt258\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 44035,  2138,  1158, 44035, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.0820,  0.3007,  0.2216]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt259\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 12230,   273,   323, 10181, 44035, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.9333, -1.0471, -1.0477]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt260\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  1305,   273,   323, 44035, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.4662, -1.0721, -0.5756]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt261\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,   273,   323, 46551, 46551, 44035, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ...,  0.7810, -1.1098, -1.6276]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt262\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 12230, 44035, 46551,  1305, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ...,  0.1569, -0.1037, -0.6822]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt263\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2172,   273,   323,  9068,  5285, 10181, 49407,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.1775, -0.9199, -0.6200]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt264\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2172,  2138,  1158,  9068,  5285, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.3324, -0.5914,  0.6148]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt265\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 12230, 13241,   794,  7301, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.3242, -0.5526, -0.1927]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt266\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  7301, 46551, 13241,   794, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.2064, -0.4795, -0.6675]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt267\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 22306,  9654, 13241,   794,  2138,  1158, 49407,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.4520,  0.1388, -1.0032]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt268\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  1305,  9068,  5285, 46551,  2441, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.1699, -0.1289,  0.6365]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt269\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2138,  1158, 13241,   794, 46551, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ...,  0.1207, -0.5034, -1.1575]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt270\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 44035,  2441,  7301, 49407,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.2411,  0.0287, -0.2436]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt271\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2441, 13241,   794,  1145, 28889, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.6625,  0.3109, -0.8356]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt272\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  1145, 28889, 44035, 10181, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -2.8995,  0.4244, -0.0381]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt273\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 44035,  1305,  1305, 22306, 22306, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.1845,  0.4198, -1.1548]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt274\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  1305, 44035, 12230,  9654, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.0856,  0.2652, -0.4890]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt275\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 13241,   794, 44035, 10181, 12230, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.4448,  0.0447, -0.8037]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt276\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  9654, 44035, 10181,  7301, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -2.0297,  0.3439,  0.1950]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt277\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 22306, 44035, 44035, 46551, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.2954, -0.3830, -1.2550]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt278\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  9068,  5285, 13241,   794,  7301, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.1138, -0.7472, -0.1720]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt279\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,   273,   323,  2441,  1145, 28889,  2172, 49407,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.9855, -0.7196, -1.2445]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt280\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  1305,  7301, 10181,  2441,  7301, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.8163,  1.0322,  0.1397]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt281\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,   273,   323,  1305,  2441, 13241,   794,  2441, 49407,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.5709,  0.1051, -1.6035]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt282\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  1305, 46551, 13241,   794,  9654, 22306, 49407,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ...,  0.2662, -0.2536, -1.4688]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt283\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2172, 13241,   794, 44035,   273,   323, 49407,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -2.0016, -0.4490, -0.5206]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt284\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  9068,  5285, 13241,   794, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.0744, -0.3557, -0.7103]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt285\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  9654,  2138,  1158,  9068,  5285, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ...,  0.1827,  0.0186,  0.4135]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt286\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2138,  1158, 10181, 10181,   273,   323,  2172, 49407,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.6624,  0.5797, -0.7863]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt287\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  9068,  5285, 13241,   794, 12230, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.2980, -0.7100, -0.8115]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt288\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  9654,   273,   323,   273,   323,  1305,   273,   323, 49407,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ...,  0.1751, -0.6355, -0.7715]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt289\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2138,  1158,  1145, 28889, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.1355,  0.1133, -0.5300]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt290\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 13241,   794, 12230,  9654, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.7152, -0.0280, -0.7053]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt291\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 22306,  9068,  5285,   273,   323, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ...,  0.4419, -0.8154, -1.2512]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt292\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 22306,  2172,  7301, 44035, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.2554, -0.2388, -1.1375]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt293\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  9068,  5285, 46551,  7301, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.8092, -0.8153,  0.5202]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt294\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 22306, 10181,  1305, 10181,  9654,   273,   323, 49407,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.8696,  0.1990, -1.4491]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt295\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2138,  1158,  2441, 12230,  2441, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.9396,  0.5123, -1.1365]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt296\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 46551, 44035,  2172, 10181, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.5115, -0.3503, -0.5789]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt297\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 10181,  9068,  5285,  2138,  1158, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.7292,  0.2480, -0.2056]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt298\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  1305,  9068,  5285,  9654,  2172, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.1313,  0.1200,  0.4730]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt299\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2441, 10181,  9068,  5285, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.3238, -0.1669,  0.1274]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt300\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 12230, 22306,  1305,  1305,  1305,  9654, 49407,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ...,  0.1203,  0.3466, -0.7648]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt301\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2441, 10181,  2172,   273,   323,  1305, 49407,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.2777,  0.6228, -0.5926]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt302\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 13241,   794, 22306, 12230, 22306, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.0264,  0.3009, -1.6084]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt303\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 46551, 46551,   273,   323,  2172, 13241,   794, 49407,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ...,  0.3058, -0.8945, -1.1400]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt304\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2441,  7301,  2138,  1158, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.6923, -0.0345,  0.1625]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt305\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 22306, 10181,  2441, 46551, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.0669,  0.4023, -1.6333]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt306\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,   273,   323, 44035, 22306, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.1124, -0.5387, -1.8585]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt307\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,   273,   323,  2172, 22306,  1305,  2172, 49407,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ...,  0.1987, -0.5770, -1.9252]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt308\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 12230, 13241,   794,  9654,  7301, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.0639, -0.6866, -0.2197]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt309\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 22306, 10181,  7301,  2138,  1158, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.2765,  0.9450, -0.2836]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt310\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 22306, 46551, 12230, 44035, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.2702, -0.3802, -1.2916]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt311\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  7301,  1305,  9654,  2172, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.4164,  0.1217, -0.1358]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt312\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2172,  2172, 10181, 22306, 10181, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -2.0234,  0.5307, -1.2663]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt313\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  9654,   273,   323, 22306,  2441,  2172, 49407,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.3689, -0.1594, -1.1312]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt314\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  1145, 28889,  9654,  2138,  1158, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.5812,  0.0580, -0.1068]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt315\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  7301,  1305, 13241,   794,  2172,  2172, 49407,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.8708, -0.8855, -0.4543]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt316\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 22306,  9654,  2172, 12230,  1305, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.7396,  0.7790, -0.7688]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt317\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 12230, 46551,  1145, 28889,  1305, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ...,  0.3482, -0.0265, -0.4159]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt318\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 44035, 12230, 10181,  1305, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.3891,  0.8528, -0.1747]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt319\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2138,  1158,  2172,  2441,  1305,  2172, 49407,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.8692,  0.1849, -0.1672]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt320\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  9654, 13241,   794,  2172, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.9026,  0.1498, -0.7939]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt321\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  1305, 13241,   794,  2441, 10181,  1305, 49407,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.9129,  1.0177, -0.6828]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt322\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,   273,   323,  1145, 28889, 10181, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.5411, -0.4286, -1.0318]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt323\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2138,  1158,  9068,  5285,  2441, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ...,  0.0186,  0.1672, -0.0679]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt324\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 13241,   794,  2441, 10181, 10181, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.0503,  0.3846, -1.3611]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt325\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2172,  2172,  2441, 10181,  2172, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.7216,  0.2069, -0.3089]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt326\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 10181,  9654,  2441, 12230, 22306, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.4708,  0.9726, -1.5829]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt327\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  9654,  1145, 28889, 12230,  1305, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.9707, -0.1221, -0.3901]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt328\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  9654,  2138,  1158, 10181, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.9253,  1.2129, -0.3659]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt329\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 12230, 13241,   794,  2138,  1158,  9654, 49407,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.4664, -0.2212, -0.7224]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt330\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  9068,  5285, 12230, 46551,  2172, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ...,  0.2877, -0.4365, -0.3514]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt331\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,   273,   323, 46551,  1305,   273,   323,  2172,  2441, 49407,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ...,  0.5711, -1.3234, -2.0376]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt332\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 44035,  2138,  1158,  2441, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.0454,  0.7951, -0.1825]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt333\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  9654, 22306, 46551,  2138,  1158, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.0460,  0.3377, -1.3731]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt334\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  1305, 44035,  9654,  7301,  2172, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.8683, -0.2163, -0.3277]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt335\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 12230,  2441,  1145, 28889, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.8160,  0.1019, -0.8472]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt336\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 46551, 10181, 13241,   794, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.6145,  0.1748, -1.0837]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt337\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 12230,  7301, 10181,  1305, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.8771,  0.2280,  0.1491]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt338\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2138,  1158, 13241,   794, 22306,  9654, 49407,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.1458, -0.1101, -1.3259]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt339\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 22306,   273,   323,  1145, 28889,  1305, 49407,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.5610, -0.3486, -0.9373]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt340\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,   273,   323,  1305,  1305,  2172, 13241,   794, 49407,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.3942, -0.4600, -0.7025]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt341\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  9068,  5285, 10181, 22306, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.8622, -0.1381, -0.9952]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt342\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 13241,   794, 46551,  9654, 10181, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.2301,  0.4560, -1.0211]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt343\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  1305,  2441,  1145, 28889, 12230, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.1862,  0.6655, -0.6615]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt344\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 22306,  9068,  5285,  2172, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.4546, -0.1050, -0.3507]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt345\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 10181, 13241,   794, 44035, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -2.5273,  0.1855, -0.9131]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt346\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  9068,  5285,  9068,  5285, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.0266, -0.6639,  1.0066]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt347\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  9068,  5285,  1145, 28889, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.8345,  0.0804, -0.2833]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt348\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 22306, 46551, 46551, 46551, 12230, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ...,  1.1921, -0.0448, -1.3362]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt349\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 44035,  7301,  1145, 28889, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -2.4886,  0.2289, -0.7679]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt350\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 13241,   794, 22306, 13241,   794, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.1095,  0.3005, -1.3589]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt351\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 13241,   794,  7301, 12230, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.7115, -0.4313, -0.2029]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt352\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 13241,   794, 13241,   794, 44035, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -2.2067, -0.1283, -0.7743]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt353\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  1145, 28889,  2138,  1158,  2172, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.0309,  0.0469, -0.4516]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt354\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 10181,  9654,  7301,  2138,  1158, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.4653,  0.3707, -0.1409]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt355\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 22306,  2172,  9654,  2441, 44035, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.1651, -0.0933, -1.2802]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt356\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 46551, 13241,   794,  1145, 28889, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.6513, -0.4539, -0.7446]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt357\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  1145, 28889, 46551,  1305, 12230, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.1525, -0.5644, -0.2203]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt358\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2138,  1158, 12230,  9068,  5285, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.1264, -0.8901,  0.1285]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt359\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  7301,  7301,   273,   323,  7301, 22306, 49407,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.4146, -0.4338, -0.9242]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt360\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 12230, 44035, 46551, 10181, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.6522, -0.0599, -0.5668]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt361\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2441,  7301,  9654, 22306, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.2867,  0.7283, -1.0694]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt362\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 46551, 13241,   794, 12230,   273,   323,  7301, 49407,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.7967, -1.5004, -0.7560]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt363\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 10181, 12230, 46551,  1305, 12230, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ...,  0.3979, -0.0388, -1.0415]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt364\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2138,  1158,  1305, 44035,  1305, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.4425,  0.2330, -0.4525]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt365\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2172, 44035, 22306, 22306, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.8511, -0.2500, -1.4308]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt366\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  7301,   273,   323, 22306,  7301, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.4959, -0.6169, -1.1435]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt367\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 22306,  1305,  1145, 28889,  2172, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.9901, -0.2364, -0.9152]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt368\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 10181,  9068,  5285, 49407,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.4454, -0.2478,  0.1634]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt369\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2172,  9068,  5285, 44035, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.6575, -0.5447, -0.1995]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt370\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  7301,  7301, 44035,  1305, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.2864, -0.5406,  0.1660]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt371\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  9068,  5285, 44035,  9654, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.4642, -0.0633,  0.1048]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt372\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  9654,  9068,  5285,  2441,  1305, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.2221, -0.0098,  0.0432]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt373\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 22306,   273,   323,  1305, 13241,   794, 22306, 49407,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ...,  0.0341, -0.2838, -1.0941]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt374\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 10181,   273,   323,  7301, 10181,  1305,  2172, 49407,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.9090, -0.5422, -0.2017]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt375\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2172, 13241,   794,  2138,  1158, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.1617, -0.0637, -1.1108]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt376\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  9654,  2138,  1158,  9068,  5285, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ...,  0.1827,  0.0186,  0.4135]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt377\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,   273,   323,  2138,  1158, 44035,  9654, 49407,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.3797, -0.6766, -1.1510]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt378\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 46551,  7301,  2441, 12230,  2172, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.1893,  0.2089, -1.0729]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt379\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  1305, 12230,  9654,  7301,  7301, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.8757,  0.0918,  0.0333]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt380\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  1145, 28889,  2172, 46551, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.9645, -1.6707, -0.9612]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt381\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 13241,   794,   273,   323,   273,   323,  9654,  7301, 49407,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.0537, -0.8993, -0.5705]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt382\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2441, 46551,  9068,  5285, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ...,  0.6552, -0.2994, -0.2674]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt383\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  1305, 22306,  1305, 10181,   273,   323, 12230, 49407,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.4142, -0.2411, -1.1208]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt384\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  1305, 10181, 44035,  2138,  1158, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.1827,  0.7716, -0.3113]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt385\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 44035,  7301, 22306,  7301, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.1431,  0.4254, -0.7686]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt386\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  7301, 46551, 10181,  9654,  2441, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.4015, -0.2020, -0.1334]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt387\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,   273,   323, 10181, 44035, 46551, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.3143, -1.1074, -1.9261]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt388\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  7301,  9068,  5285,   273,   323, 10181, 49407,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.9334, -1.5563,  0.4080]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt389\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 13241,   794, 13241,   794, 22306, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.2167,  0.1949, -1.6244]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt390\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 44035, 44035, 44035, 49407,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.9379, -0.2161,  0.2662]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt391\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 46551, 13241,   794,  2138,  1158,  9654, 49407,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.4959, -0.2162, -1.1918]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt392\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  9068,  5285,  9068,  5285, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.0266, -0.6639,  1.0066]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt393\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  9068,  5285, 22306,  9654, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ...,  0.1971,  0.0125, -0.3987]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt394\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  7301,  2441,  2138,  1158, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.7431,  0.2894, -0.6226]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt395\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,   273,   323, 10181, 46551,  1145, 28889, 49407,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.2400, -1.3535, -2.1411]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt396\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 10181, 12230,  2441,   273,   323,  2172, 49407,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.9074, -0.3161, -1.7976]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt397\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 10181,  2441,   273,   323,  9654,  2172, 12230, 49407,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.2070,  0.1370, -1.2532]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt398\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 12230, 10181, 46551,  2138,  1158,   273,   323, 49407,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.4392, -0.5844, -2.0315]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt399\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  9068,  5285,  7301,   273,   323, 12230, 49407,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.4545, -2.1032, -0.1388]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt400\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  1305,  2441,  1145, 28889, 10181, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.6846,  0.8768, -0.6449]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt401\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 22306, 10181, 10181, 13241,   794, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.8347,  0.9164, -1.4451]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt402\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2441,  9654, 22306, 44035, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.5662,  0.0042, -1.3598]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt403\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2172, 10181,   273,   323, 12230, 44035, 49407,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.1165, -1.1009, -1.0749]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt404\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2138,  1158,  2441,  9068,  5285, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ...,  0.2261, -0.1755,  0.1519]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt405\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  9068,  5285,  1305,  2172, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.4915, -0.3077,  0.9641]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt406\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 22306, 22306,  9068,  5285, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ...,  0.3841, -0.2207, -0.6247]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt407\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2172,  1305, 10181, 44035, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -2.4944, -1.3050, -0.3598]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt408\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  7301, 13241,   794,   273,   323, 10181,  9654, 49407,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.9845, -0.5062, -0.7526]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt409\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  1145, 28889, 12230,  2441, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.6572,  0.5636, -0.5932]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt410\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,   273,   323,  1145, 28889, 22306, 10181, 49407,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.0873, -0.2273, -1.2571]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt411\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 22306, 46551, 46551,  7301, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.1696,  0.1367, -0.5847]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt412\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 22306, 46551,  7301, 13241,   794,   273,   323, 49407,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.1468, -0.4028, -1.3403]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt413\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 12230, 46551, 46551,  2441,  2441, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ...,  0.7422,  0.0545, -0.8625]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt414\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2138,  1158,  1305,   273,   323,  1305, 49407,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ...,  0.2085, -0.2282, -1.0907]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt415\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  1145, 28889,   273,   323,   273,   323,  2172,  1305, 49407,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.2725, -1.5767, -0.2390]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt416\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2441, 22306,  2172, 22306,   273,   323, 10181, 49407,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.6340,  0.0985, -1.7483]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt417\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  1305,  9068,  5285,  1305, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.0755, -0.2047,  1.2203]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt418\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2138,  1158,  2441,  9068,  5285, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ...,  0.2261, -0.1755,  0.1519]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt419\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  1305,  9654, 10181,  1305,   273,   323,  1305, 49407,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.4788,  0.3804, -0.3396]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt420\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  1305,  1145, 28889, 46551, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.3846, -0.7591, -0.8447]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt421\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 46551,  2172,  2441,  1145, 28889, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.2343, -1.1980, -0.9622]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt422\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 22306,  1305, 22306,  2172, 22306, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.7630, -0.0245, -1.0041]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt423\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  9068,  5285, 22306, 12230, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ...,  0.0748, -0.3482, -0.7348]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt424\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  1305, 10181,  7301, 10181, 46551, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.6665, -0.5296, -0.2750]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt425\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 13241,   794,  1145, 28889,  1305, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.1095,  0.0748, -0.2218]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt426\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 13241,   794,  1145, 28889, 46551, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.3470, -0.4329, -0.9195]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt427\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  1305, 12230,  1305,  1145, 28889, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.2688, -0.0630,  0.0273]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt428\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  9068,  5285,  9068,  5285, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.0266, -0.6639,  1.0066]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt429\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 13241,   794,  2441, 12230, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.4978,  0.3292, -1.3128]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt430\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 46551,  9654,  2441,  2138,  1158, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ...,  0.0021,  0.3965, -0.7524]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt431\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  1305,  2172,  9068,  5285, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ...,  0.0383, -0.1851,  1.2693]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt432\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2138,  1158,  9654, 12230,  1305, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.0101,  0.3911, -0.1116]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt433\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  1145, 28889, 44035,  9654, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.2843,  0.0672, -0.4170]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt434\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 44035,   273,   323,  9654,   273,   323, 49407,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.8055, -0.5495, -0.6611]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt435\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  9068,  5285,  7301,  9654,  1305, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.2515, -0.2883,  0.2647]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt436\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 10181,  7301,  9654, 13241,   794, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.8996, -0.0590, -0.2356]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt437\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  9654,  9068,  5285,  2441, 12230, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.3645,  0.3662, -0.3633]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt438\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 13241,   794, 13241,   794, 44035, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -2.2067, -0.1283, -0.7743]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt439\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2441,  7301,  2138,  1158, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.6923, -0.0345,  0.1625]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt440\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 46551, 44035, 22306, 13241,   794, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ...,  0.2218, -0.3072, -1.4638]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt441\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 22306, 22306, 13241,   794, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ...,  0.1020,  0.2924, -1.1842]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt442\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 13241,   794,  2138,  1158,   273,   323, 49407,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.6305, -0.3148, -1.3600]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt443\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,   273,   323,   273,   323,  9654,  2441,  7301,  7301, 49407,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.9553, -0.1471, -1.0655]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt444\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,   273,   323,  1145, 28889, 12230, 12230, 49407,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.4565, -0.7881, -0.6866]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt445\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  1145, 28889, 22306, 44035, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.4187, -0.3562, -1.2798]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt446\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 22306,  9068,  5285,  2172,  9654, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.1481, -0.2410, -0.5228]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt447\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2138,  1158,  1145, 28889,  1305, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.9261,  0.1695, -0.0856]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt448\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  1305,  9068,  5285, 49407,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ...,  0.5375, -0.3056,  1.1847]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt449\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 46551, 22306,  9654,  1305, 46551, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ...,  0.0329, -0.1719, -1.3764]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt450\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 10181,  2172, 22306,  9068,  5285, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.5052,  0.1211, -0.9785]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt451\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 12230, 12230,  1145, 28889,   273,   323, 49407,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.4202, -0.8416, -0.4187]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt452\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 12230,  1145, 28889, 12230, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.0517, -0.0611, -0.3926]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt453\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 44035, 10181, 22306, 10181, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -2.2676,  0.4138, -1.1956]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt454\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 44035,  1145, 28889, 49407,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -2.2198,  0.0310, -0.9985]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt455\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2172,  2138,  1158, 10181, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.5605,  0.6139, -0.2069]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt456\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2172,  2172,  1145, 28889,   273,   323, 49407,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.5653, -0.6612, -0.9035]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt457\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  9068,  5285, 22306, 22306,  2172, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.0674, -0.3364, -0.7058]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt458\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2441,  2172,   273,   323, 44035, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.9630, -1.1117, -0.7042]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt459\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  1305,  2441, 22306,  2138,  1158, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ...,  0.4750,  0.8827, -1.2140]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt460\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  9068,  5285, 12230, 12230, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.1767, -0.6272, -0.3008]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt461\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  1305,  9654, 46551,  7301,  1305, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.5545, -0.2254, -0.1266]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt462\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2172, 22306,  2441,  9068,  5285, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.3447,  0.1007, -0.4243]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt463\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2138,  1158,  9654, 44035, 12230, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.6704, -0.4127, -0.4937]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt464\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 46551, 10181, 10181,  2138,  1158, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.3329,  0.2835, -0.8484]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt465\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 12230,  7301,  9068,  5285, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.7684, -1.0589,  0.3889]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt466\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  1145, 28889, 46551, 46551, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.4055, -0.6757, -0.4616]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt467\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  9068,  5285, 13241,   794, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.0744, -0.3557, -0.7103]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt468\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 44035,  2441,   273,   323, 22306, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.7906, -0.5172, -1.4480]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt469\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2138,  1158, 10181,  2138,  1158, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.6833,  0.9974,  0.3583]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt470\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  9068,  5285,  7301,  2441, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.8287,  0.0880, -0.4182]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt471\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2138,  1158,  9068,  5285, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.0892, -0.5539,  0.5245]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt472\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 44035,   273,   323, 46551,  9654,  7301, 49407,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.1922, -0.2510, -0.8551]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt473\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2138,  1158, 22306,  2172,  2172, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.0288,  0.0814, -0.9513]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt474\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 46551, 22306,   273,   323,  1145, 28889, 49407,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.2186, -0.9690, -1.5221]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt475\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2138,  1158,  2441, 22306,  2441, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.4730,  1.1755, -0.9599]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt476\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2172,  7301,  9068,  5285, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.5511, -0.3625,  0.2986]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt477\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2441,  2138,  1158, 46551, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ...,  0.3292, -0.0459, -0.4671]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt478\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2172, 12230,  9654, 22306,  9654, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.7548,  0.5600, -1.2746]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt479\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2138,  1158, 12230,  1145, 28889, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.0258, -0.2767, -0.2050]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt480\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 44035, 12230,  9654,  7301, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.8013, -0.2923, -0.0330]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt481\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2138,  1158, 12230,  7301, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.4249, -0.6809,  0.0325]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt482\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2138,  1158, 13241,   794,   273,   323,  2172, 49407,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.9300, -0.9242, -1.0692]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt483\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  9068,  5285,   273,   323, 44035, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.0536, -1.5138, -0.4223]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt484\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 46551, 44035,  7301,  7301, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.0525, -0.5063, -0.5895]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt485\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  1145, 28889, 44035,  2172, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.9758, -0.6013, -0.0121]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt486\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 13241,   794,  7301,  9068,  5285, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.0910, -0.6363, -0.2549]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt487\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  9068,  5285, 10181,  2172,   273,   323,   273,   323, 49407,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.9882, -0.5389, -0.0497]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt488\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 46551, 22306,  1145, 28889, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.8391, -0.3921, -1.0576]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt489\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2138,  1158,  2172, 13241,   794, 10181, 49407,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.1298,  0.3352, -0.2878]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt490\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  7301,  1145, 28889,  9654, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.5248,  0.0799, -0.7532]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt491\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2138,  1158,   273,   323, 12230,  2138,  1158, 49407,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.3468, -1.1930, -1.0223]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt492\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 10181,  1305,  9654,   273,   323,  2441,  9654, 49407,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.8854,  0.7532, -0.3975]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt493\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  9068,  5285, 44035,  1305, 49407,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.4408, -0.4713,  0.2777]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt494\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2138,  1158,  1145, 28889,  9654, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -1.0861, -0.1085, -0.3720]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt495\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406, 46551, 12230,  9654,  1145, 28889, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.3327, -0.6925, -1.4283]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt496\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  7301,  2172, 10181, 22306, 10181, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -2.7757,  0.4853, -0.8051]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt497\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2138,  1158,   273,   323, 13241,   794,  9654, 49407,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.6176, -0.4736, -0.8571]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt498\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2441,  7301, 46551, 12230, 12230, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.5009,  0.0215, -0.3253]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt499\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 77])\n",
            "tensor([[49406,  2441,  1145, 28889,  9654, 12230, 49407,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[-0.3884,  0.0229, -0.0522,  ..., -0.9305,  0.3823, -0.5539]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 9216])\n",
            "Computing text embedding for Prompt500\n",
            "torch.Size([1, 768])\n",
            "Process completed and dataset is generated\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Declare a variable\n",
        "a = torch.tensor([2, 3, 4, 5])\n",
        "# Using unsqueeze() method to add dimension\n",
        "print(a.shape)\n",
        "m=torch.unsqueeze(a, 0)\n",
        "# Print output\n",
        "print(m.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UNdGVJw2Ncvo",
        "outputId": "f962740a-4ad3-4d73-db9b-a481d0b7adc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4])\n",
            "torch.Size([1, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lXoU-XhmrTP_",
        "outputId": "4c4164ce-dae3-4af8-c78c-85a124ecd489"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Elm auto-encoder implementation"
      ],
      "metadata": {
        "id": "T6FB9T_NF8HI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import json\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "\n",
        "class ELMAutoEncoder(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size, batch_size=1, use_gpu=True):\n",
        "        super(ELMAutoEncoder, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.batch_size = batch_size\n",
        "        self.use_gpu = use_gpu\n",
        "        if self.use_gpu and torch.cuda.is_available():\n",
        "            self.device = torch.device(\"cuda\")\n",
        "        else:\n",
        "            self.device = torch.device(\"cpu\")\n",
        "            print(\"Warning: CUDA not available, using CPU.\")\n",
        "        self.set_random_seed()    \n",
        "        self.weight = nn.Parameter(torch.randn(input_size, hidden_size, dtype=torch.float, device=self.device))\n",
        "        self.bias = nn.Parameter(torch.randn(hidden_size, device=self.device))\n",
        "        self.beta = nn.Parameter(torch.randn(hidden_size, output_size, device=self.device))\n",
        "        self.activation_hidden = nn.ReLU()\n",
        "        self.activation_output = nn.Identity()\n",
        "        \n",
        "    def forward(self, x):\n",
        "        h = self.activation_hidden(x @ self.weight + self.bias)       \n",
        "        y_pred = torch.sigmoid(h @ self.beta)  # apply sigmoid to output\n",
        "        return y_pred\n",
        "\n",
        "    def set_random_seed(self):\n",
        "        seed = int(time.time())\n",
        "        torch.manual_seed(seed)\n",
        "        np.random.seed(seed)\n",
        "    \n",
        "    def fit(self, x_train,targets_train, n_neurons):\n",
        "        H = self.activation_hidden(torch.matmul(x_train.float(), self.weight.float()) + self.bias.float())\n",
        "     #  H = self.activation_hidden(torch.matmul(x_train.float(), self.weight) + self.bias)\n",
        "        print('output of hiddenlayer',H.shape)\n",
        "        H_inv = torch.pinverse(H)\n",
        "\n",
        "        beta = torch.matmul(H_inv, targets_train.float())\n",
        "\n",
        "        self.beta = nn.Parameter(beta)\n",
        "        self.output_weight = nn.Parameter(self.beta)\n",
        "        print('output weight matrix',self.output_weight.shape)\n",
        "        self.bias = nn.Parameter(torch.zeros((n_neurons,)))\n",
        "        return self\n",
        "    \n",
        "    def encode(self, x):\n",
        "       # h = self.activation_hidden(x.float() @ self.weight.t())\n",
        "        print('input to encoder',x.shape)\n",
        "        h=self.activation_hidden(torch.matmul(x.float(), self.weight.float()) + self.bias.float())\n",
        "        return h\n",
        "    \n",
        "    def decode(self, h):\n",
        "        x_pred = self.activation_output(h @ self.output_weight)\n",
        "        return x_pred\n",
        "    \n",
        "    def clear_memory(self):\n",
        "        if self.use_gpu and torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()\n",
        "        else:\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "def reconstruction_error(model,data,targets_train):\n",
        "    with torch.no_grad():\n",
        "        encoded = model.encode(data)\n",
        "        print('encoded.shape',encoded.shape)\n",
        "        decoded = model.decode(encoded)\n",
        "        print('decoded',decoded.shape)\n",
        "        mse_loss = nn.MSELoss()(decoded, targets_train)\n",
        "        cos_sim = cosine_similarity(targets_train.reshape(targets_train.shape[0], -1), decoded.reshape(decoded.shape[0], -1))\n",
        "        cos_dis=1 - cos_sim.mean()\n",
        "        return mse_loss.item(),cos_dis\n",
        "\n",
        "def load_prompts(file_path):\n",
        "    with open(file_path) as f:\n",
        "        prompts = json.load(f)\n",
        "    return prompts\n",
        "\n",
        "def prepare_data(prompts):\n",
        "    text_features = []\n",
        "    for prompt in prompts:\n",
        "        text_feature = np.array(prompt['word_embedding'])\n",
        "        text_features.append(text_feature)\n",
        "    return text_features\n",
        "\n",
        "def prepare_targets(prompts):\n",
        "    clip_embeddings = []\n",
        "    for prompt in prompts:\n",
        "        clip_embedding = np.array(prompt['clip_embedding'])\n",
        "        clip_embeddings.append(clip_embedding)\n",
        "    return clip_embeddings\n",
        "\n",
        "\n",
        "\n",
        "prompts = load_prompts('/content/prompts_and_embeddings.json')\n",
        "\n",
        "# Prepare data and targets\n",
        "data = prepare_data(prompts)\n",
        "targets = prepare_targets(prompts)\n",
        "hidden_size=500\n",
        "# Convert to PyTorch tensors\n",
        "\n",
        "\n",
        "# Split the data into train and test sets\n",
        "data_train, data_test, targets_train, targets_test = train_test_split(data, targets, test_size=0.2, random_state=42)\n",
        "\n",
        "data_train=torch.tensor(data_train)\n",
        "data_test=torch.tensor(data_test)\n",
        "targets_train=torch.tensor(targets_train)\n",
        "targets_test=torch.tensor(targets_test)\n",
        "#print(targets_test.shape[1])\n",
        "autoencoder = ELMAutoEncoder(data_train.shape[1], hidden_size,targets_test.shape[1])\n",
        "autoencoder.fit(data_train,targets_train, hidden_size)\n",
        "#print(data_train.shape)\n",
        "train_reconstruction_error,cos_dis = reconstruction_error(autoencoder,data_train,targets_train)\n",
        "# Calculate the mean squared error and cosine distance\n",
        "print('train mse error','{:.15f}'.format(train_reconstruction_error))\n",
        "print('train cosine distance','{:.15f}'.format(cos_dis))\n",
        "\n",
        "test_reconstruction_error,cos_dis = reconstruction_error(autoencoder,data_test,targets_test)\n",
        "print('test mse error',test_reconstruction_error)\n",
        "print('test cosine distance',cos_dis)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4fu_CG0LfQgs",
        "outputId": "5b7d2d5d-a092-4617-bda8-a277d9a14673"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: CUDA not available, using CPU.\n",
            "output of hiddenlayer torch.Size([400, 500])\n",
            "output weight matrix torch.Size([500, 768])\n",
            "input to encoder torch.Size([400, 9216])\n",
            "encoded.shape torch.Size([400, 500])\n",
            "decoded torch.Size([400, 768])\n",
            "train mse error 0.000021905812931\n",
            "train cosine distance 0.393875436133021\n",
            "input to encoder torch.Size([100, 9216])\n",
            "encoded.shape torch.Size([100, 500])\n",
            "decoded torch.Size([100, 768])\n",
            "test mse error 0.00043785497122362274\n",
            "test cosine distance 0.44909698674978304\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List\n",
        "import torch\n",
        "from torch import nn\n",
        "from transformers import CLIPTokenizer, CLIPTextModel\n",
        "\n",
        "\n",
        "class CLIPTextEmbedder(nn.Module):\n",
        "    \"\"\"\n",
        "    ## CLIP Text Embedder\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, version: str = \"openai/clip-vit-large-patch14\", device=\"cuda:0\", max_length: int = 24):\n",
        "        \"\"\"\n",
        "        :param version: is the model version\n",
        "        :param device: is the device\n",
        "        :param max_length: is the max length of the tokenized prompt\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        # Load the tokenizer\n",
        "        self.tokenizer = CLIPTokenizer.from_pretrained(version)\n",
        "        print(self.tokenizer)\n",
        "        # Load the CLIP transformer\n",
        "        self.transformer = CLIPTextModel.from_pretrained(version).eval()\n",
        "\n",
        "        #self.device = device\n",
        "        self.device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "  \n",
        "        self.max_length = max_length\n",
        "\n",
        "    def forward(self, prompts: List[str]):\n",
        "        \"\"\"\n",
        "        :param prompts: are the list of prompts to embed\n",
        "        \"\"\"\n",
        "        # Tokenize the prompts\n",
        "        batch_encoding = self.tokenizer(prompts, truncation=True, max_length=self.max_length, return_length=True,\n",
        "                                        return_overflowing_tokens=False, padding=\"max_length\", return_tensors=\"pt\")\n",
        "        # Get token ids\n",
        "        tokens = batch_encoding[\"input_ids\"].to(self.device)\n",
        "        # Get CLIP embeddings\n",
        "        return self.transformer(input_ids=tokens).last_hidden_state\n",
        "\n",
        "print(\"start\")\n",
        "x = CLIPTextEmbedder()\n",
        "out = x.forward(prompts=[\"space marines\"])\n",
        "out=torch.flatten(out)\n",
        "print(torch.Tensor.size(out))\n",
        "print(out)\n",
        "print(\"finish\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6f4N3NeRzbIi",
        "outputId": "fced10b4-9e69-4075-c864-a05b05e31bd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "start\n",
            "CLIPTokenizer(name_or_path='openai/clip-vit-large-patch14', vocab_size=49408, model_max_length=77, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': AddedToken(\"<|startoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'eos_token': AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'unk_token': AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'pad_token': '<|endoftext|>'}, clean_up_tokenization_spaces=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at openai/clip-vit-large-patch14 were not used when initializing CLIPTextModel: ['vision_model.encoder.layers.21.self_attn.k_proj.bias', 'vision_model.encoder.layers.14.mlp.fc2.bias', 'vision_model.encoder.layers.14.self_attn.q_proj.bias', 'vision_model.encoder.layers.6.self_attn.v_proj.bias', 'vision_model.encoder.layers.16.mlp.fc1.bias', 'vision_model.encoder.layers.8.self_attn.out_proj.bias', 'vision_model.encoder.layers.18.self_attn.out_proj.bias', 'vision_model.encoder.layers.1.self_attn.q_proj.bias', 'vision_model.encoder.layers.18.self_attn.q_proj.bias', 'vision_model.encoder.layers.20.self_attn.q_proj.bias', 'vision_model.encoder.layers.13.self_attn.v_proj.weight', 'vision_model.encoder.layers.5.layer_norm2.weight', 'vision_model.encoder.layers.11.layer_norm2.weight', 'vision_model.encoder.layers.5.self_attn.v_proj.bias', 'vision_model.encoder.layers.13.mlp.fc2.bias', 'vision_model.encoder.layers.3.self_attn.out_proj.weight', 'vision_model.encoder.layers.12.self_attn.out_proj.weight', 'vision_model.encoder.layers.1.mlp.fc1.weight', 'vision_model.encoder.layers.0.mlp.fc1.bias', 'vision_model.encoder.layers.18.self_attn.q_proj.weight', 'vision_model.encoder.layers.9.mlp.fc2.bias', 'vision_model.encoder.layers.16.self_attn.out_proj.weight', 'vision_model.encoder.layers.6.self_attn.q_proj.bias', 'vision_model.encoder.layers.18.self_attn.v_proj.weight', 'vision_model.encoder.layers.0.mlp.fc2.bias', 'vision_model.encoder.layers.18.layer_norm1.weight', 'vision_model.encoder.layers.2.mlp.fc2.bias', 'vision_model.encoder.layers.21.self_attn.out_proj.weight', 'vision_model.encoder.layers.18.layer_norm2.weight', 'vision_model.embeddings.patch_embedding.weight', 'vision_model.encoder.layers.4.mlp.fc2.bias', 'vision_model.encoder.layers.20.layer_norm2.bias', 'vision_model.encoder.layers.11.self_attn.q_proj.weight', 'vision_model.encoder.layers.18.layer_norm2.bias', 'vision_model.encoder.layers.13.self_attn.v_proj.bias', 'vision_model.encoder.layers.16.self_attn.k_proj.weight', 'vision_model.encoder.layers.6.mlp.fc2.weight', 'vision_model.encoder.layers.6.mlp.fc1.weight', 'vision_model.encoder.layers.10.self_attn.v_proj.bias', 'vision_model.encoder.layers.7.self_attn.v_proj.bias', 'vision_model.encoder.layers.12.self_attn.k_proj.weight', 'vision_model.encoder.layers.8.layer_norm1.bias', 'vision_model.encoder.layers.9.layer_norm1.bias', 'vision_model.encoder.layers.16.self_attn.k_proj.bias', 'vision_model.encoder.layers.23.self_attn.q_proj.bias', 'vision_model.encoder.layers.1.mlp.fc2.weight', 'vision_model.encoder.layers.8.self_attn.out_proj.weight', 'vision_model.encoder.layers.1.self_attn.v_proj.weight', 'vision_model.encoder.layers.11.self_attn.k_proj.bias', 'vision_model.encoder.layers.14.self_attn.v_proj.bias', 'vision_model.encoder.layers.4.self_attn.v_proj.bias', 'vision_model.encoder.layers.10.self_attn.k_proj.weight', 'vision_model.encoder.layers.1.self_attn.k_proj.weight', 'vision_model.encoder.layers.10.self_attn.out_proj.bias', 'vision_model.encoder.layers.22.mlp.fc1.bias', 'vision_model.encoder.layers.3.layer_norm1.weight', 'vision_model.encoder.layers.20.self_attn.out_proj.weight', 'vision_model.encoder.layers.14.self_attn.out_proj.bias', 'vision_model.encoder.layers.16.mlp.fc2.weight', 'vision_model.embeddings.position_embedding.weight', 'vision_model.encoder.layers.13.mlp.fc1.weight', 'vision_model.encoder.layers.17.mlp.fc1.bias', 'vision_model.encoder.layers.19.layer_norm1.weight', 'vision_model.encoder.layers.1.self_attn.k_proj.bias', 'vision_model.encoder.layers.23.self_attn.q_proj.weight', 'vision_model.encoder.layers.5.layer_norm1.weight', 'vision_model.encoder.layers.22.self_attn.out_proj.weight', 'vision_model.encoder.layers.0.self_attn.v_proj.bias', 'vision_model.encoder.layers.23.self_attn.v_proj.bias', 'vision_model.encoder.layers.1.self_attn.q_proj.weight', 'vision_model.encoder.layers.7.mlp.fc1.bias', 'vision_model.encoder.layers.4.self_attn.k_proj.weight', 'vision_model.encoder.layers.11.layer_norm1.bias', 'vision_model.encoder.layers.3.self_attn.k_proj.weight', 'vision_model.encoder.layers.7.layer_norm1.bias', 'vision_model.encoder.layers.19.mlp.fc2.bias', 'vision_model.encoder.layers.0.self_attn.v_proj.weight', 'vision_model.encoder.layers.6.self_attn.q_proj.weight', 'vision_model.encoder.layers.18.self_attn.k_proj.bias', 'vision_model.encoder.layers.2.layer_norm2.bias', 'vision_model.encoder.layers.22.self_attn.q_proj.bias', 'vision_model.encoder.layers.2.mlp.fc2.weight', 'vision_model.encoder.layers.9.self_attn.out_proj.weight', 'vision_model.encoder.layers.21.mlp.fc2.bias', 'vision_model.encoder.layers.1.layer_norm2.bias', 'vision_model.encoder.layers.17.layer_norm1.weight', 'vision_model.encoder.layers.18.mlp.fc2.weight', 'vision_model.encoder.layers.1.self_attn.v_proj.bias', 'vision_model.encoder.layers.11.self_attn.v_proj.weight', 'vision_model.encoder.layers.13.self_attn.out_proj.bias', 'vision_model.encoder.layers.10.layer_norm2.bias', 'vision_model.encoder.layers.9.layer_norm1.weight', 'vision_model.encoder.layers.5.layer_norm2.bias', 'vision_model.encoder.layers.23.layer_norm1.weight', 'vision_model.encoder.layers.10.layer_norm1.bias', 'vision_model.encoder.layers.14.self_attn.v_proj.weight', 'vision_model.encoder.layers.0.self_attn.k_proj.bias', 'vision_model.encoder.layers.1.layer_norm2.weight', 'vision_model.encoder.layers.13.layer_norm1.weight', 'vision_model.encoder.layers.2.layer_norm1.weight', 'vision_model.encoder.layers.10.self_attn.q_proj.bias', 'vision_model.encoder.layers.5.self_attn.q_proj.bias', 'vision_model.encoder.layers.15.mlp.fc2.weight', 'vision_model.encoder.layers.6.mlp.fc1.bias', 'vision_model.encoder.layers.23.layer_norm1.bias', 'vision_model.encoder.layers.3.mlp.fc1.bias', 'vision_model.encoder.layers.4.self_attn.out_proj.weight', 'vision_model.encoder.layers.8.self_attn.k_proj.weight', 'vision_model.encoder.layers.18.self_attn.k_proj.weight', 'vision_model.encoder.layers.21.layer_norm2.weight', 'vision_model.encoder.layers.6.layer_norm1.weight', 'vision_model.encoder.layers.21.layer_norm1.bias', 'vision_model.encoder.layers.10.self_attn.v_proj.weight', 'vision_model.encoder.layers.2.self_attn.q_proj.bias', 'vision_model.encoder.layers.21.layer_norm1.weight', 'vision_model.encoder.layers.7.self_attn.k_proj.bias', 'vision_model.encoder.layers.19.layer_norm2.weight', 'vision_model.encoder.layers.12.mlp.fc1.bias', 'vision_model.encoder.layers.3.mlp.fc1.weight', 'vision_model.encoder.layers.0.mlp.fc1.weight', 'vision_model.encoder.layers.20.mlp.fc1.bias', 'vision_model.encoder.layers.8.layer_norm2.bias', 'vision_model.encoder.layers.2.self_attn.k_proj.bias', 'vision_model.encoder.layers.13.self_attn.k_proj.weight', 'vision_model.encoder.layers.12.layer_norm2.weight', 'vision_model.encoder.layers.15.self_attn.k_proj.bias', 'vision_model.encoder.layers.3.self_attn.v_proj.bias', 'vision_model.encoder.layers.20.self_attn.out_proj.bias', 'vision_model.encoder.layers.2.self_attn.v_proj.bias', 'vision_model.encoder.layers.7.layer_norm2.weight', 'vision_model.encoder.layers.12.layer_norm1.weight', 'vision_model.encoder.layers.7.self_attn.out_proj.bias', 'vision_model.encoder.layers.17.mlp.fc2.weight', 'vision_model.encoder.layers.22.self_attn.k_proj.weight', 'vision_model.encoder.layers.23.self_attn.out_proj.weight', 'vision_model.encoder.layers.11.layer_norm1.weight', 'vision_model.encoder.layers.15.self_attn.out_proj.bias', 'vision_model.encoder.layers.15.layer_norm2.bias', 'vision_model.encoder.layers.15.self_attn.q_proj.weight', 'vision_model.encoder.layers.5.self_attn.k_proj.weight', 'vision_model.encoder.layers.23.mlp.fc1.weight', 'vision_model.encoder.layers.0.layer_norm1.weight', 'vision_model.embeddings.position_ids', 'vision_model.encoder.layers.4.layer_norm2.weight', 'vision_model.encoder.layers.9.self_attn.k_proj.weight', 'vision_model.encoder.layers.12.self_attn.v_proj.bias', 'vision_model.encoder.layers.16.mlp.fc2.bias', 'vision_model.encoder.layers.19.self_attn.k_proj.bias', 'vision_model.encoder.layers.17.self_attn.q_proj.weight', 'vision_model.encoder.layers.13.layer_norm2.bias', 'vision_model.encoder.layers.0.self_attn.out_proj.bias', 'vision_model.encoder.layers.1.self_attn.out_proj.weight', 'vision_model.encoder.layers.4.self_attn.q_proj.bias', 'vision_model.encoder.layers.23.self_attn.v_proj.weight', 'vision_model.encoder.layers.17.self_attn.out_proj.weight', 'vision_model.encoder.layers.12.layer_norm1.bias', 'vision_model.encoder.layers.20.self_attn.v_proj.bias', 'vision_model.encoder.layers.20.layer_norm1.weight', 'vision_model.encoder.layers.13.self_attn.out_proj.weight', 'vision_model.encoder.layers.14.self_attn.k_proj.bias', 'vision_model.encoder.layers.4.self_attn.out_proj.bias', 'vision_model.encoder.layers.3.layer_norm2.bias', 'vision_model.encoder.layers.19.self_attn.v_proj.weight', 'vision_model.encoder.layers.7.self_attn.q_proj.weight', 'vision_model.encoder.layers.17.self_attn.out_proj.bias', 'vision_model.encoder.layers.22.layer_norm2.weight', 'vision_model.encoder.layers.16.layer_norm2.weight', 'vision_model.encoder.layers.1.mlp.fc2.bias', 'vision_model.encoder.layers.6.self_attn.k_proj.bias', 'vision_model.encoder.layers.15.self_attn.v_proj.bias', 'vision_model.encoder.layers.2.self_attn.k_proj.weight', 'vision_model.encoder.layers.6.self_attn.out_proj.bias', 'vision_model.encoder.layers.8.mlp.fc2.weight', 'vision_model.encoder.layers.15.mlp.fc1.weight', 'vision_model.encoder.layers.5.mlp.fc1.bias', 'vision_model.encoder.layers.22.self_attn.q_proj.weight', 'vision_model.encoder.layers.19.self_attn.out_proj.bias', 'vision_model.encoder.layers.21.self_attn.out_proj.bias', 'vision_model.encoder.layers.6.layer_norm2.bias', 'vision_model.encoder.layers.16.self_attn.out_proj.bias', 'vision_model.encoder.layers.6.self_attn.v_proj.weight', 'vision_model.encoder.layers.14.layer_norm1.weight', 'vision_model.encoder.layers.8.layer_norm2.weight', 'vision_model.encoder.layers.13.layer_norm2.weight', 'vision_model.encoder.layers.11.self_attn.out_proj.weight', 'vision_model.encoder.layers.10.mlp.fc2.weight', 'vision_model.encoder.layers.9.mlp.fc1.weight', 'vision_model.encoder.layers.9.self_attn.v_proj.bias', 'vision_model.encoder.layers.8.self_attn.v_proj.bias', 'vision_model.encoder.layers.1.layer_norm1.bias', 'vision_model.encoder.layers.23.layer_norm2.bias', 'vision_model.encoder.layers.12.self_attn.out_proj.bias', 'vision_model.encoder.layers.2.self_attn.out_proj.weight', 'vision_model.encoder.layers.17.layer_norm2.weight', 'logit_scale', 'vision_model.encoder.layers.20.self_attn.k_proj.weight', 'vision_model.encoder.layers.18.mlp.fc2.bias', 'vision_model.encoder.layers.3.layer_norm1.bias', 'vision_model.encoder.layers.21.mlp.fc1.bias', 'vision_model.encoder.layers.5.self_attn.q_proj.weight', 'vision_model.encoder.layers.7.layer_norm1.weight', 'vision_model.encoder.layers.11.layer_norm2.bias', 'vision_model.encoder.layers.9.self_attn.q_proj.weight', 'vision_model.encoder.layers.14.layer_norm2.bias', 'vision_model.encoder.layers.19.self_attn.q_proj.bias', 'vision_model.encoder.layers.18.self_attn.out_proj.weight', 'vision_model.encoder.layers.20.self_attn.v_proj.weight', 'vision_model.encoder.layers.5.layer_norm1.bias', 'vision_model.encoder.layers.7.mlp.fc2.bias', 'vision_model.encoder.layers.10.mlp.fc1.bias', 'vision_model.encoder.layers.20.layer_norm1.bias', 'vision_model.encoder.layers.17.self_attn.v_proj.weight', 'vision_model.encoder.layers.0.layer_norm1.bias', 'vision_model.encoder.layers.23.self_attn.k_proj.weight', 'vision_model.encoder.layers.19.layer_norm2.bias', 'vision_model.encoder.layers.8.mlp.fc2.bias', 'vision_model.encoder.layers.17.mlp.fc1.weight', 'vision_model.encoder.layers.11.mlp.fc1.bias', 'vision_model.encoder.layers.15.layer_norm2.weight', 'vision_model.encoder.layers.14.mlp.fc2.weight', 'vision_model.post_layernorm.weight', 'vision_model.encoder.layers.0.self_attn.q_proj.weight', 'vision_model.encoder.layers.7.mlp.fc1.weight', 'vision_model.encoder.layers.17.layer_norm1.bias', 'vision_model.encoder.layers.5.mlp.fc2.weight', 'vision_model.encoder.layers.8.self_attn.q_proj.weight', 'vision_model.encoder.layers.18.layer_norm1.bias', 'vision_model.encoder.layers.9.mlp.fc2.weight', 'vision_model.encoder.layers.2.mlp.fc1.bias', 'vision_model.encoder.layers.2.self_attn.q_proj.weight', 'vision_model.encoder.layers.20.self_attn.q_proj.weight', 'vision_model.encoder.layers.8.self_attn.k_proj.bias', 'vision_model.encoder.layers.20.self_attn.k_proj.bias', 'vision_model.encoder.layers.14.self_attn.k_proj.weight', 'vision_model.encoder.layers.21.self_attn.q_proj.weight', 'vision_model.encoder.layers.7.layer_norm2.bias', 'vision_model.encoder.layers.8.mlp.fc1.bias', 'vision_model.encoder.layers.4.mlp.fc1.weight', 'vision_model.encoder.layers.4.layer_norm1.bias', 'vision_model.encoder.layers.12.self_attn.k_proj.bias', 'vision_model.encoder.layers.13.layer_norm1.bias', 'vision_model.post_layernorm.bias', 'vision_model.encoder.layers.12.mlp.fc2.weight', 'vision_model.encoder.layers.12.self_attn.v_proj.weight', 'vision_model.encoder.layers.14.self_attn.out_proj.weight', 'vision_model.encoder.layers.0.self_attn.q_proj.bias', 'vision_model.encoder.layers.11.mlp.fc1.weight', 'vision_model.encoder.layers.23.mlp.fc2.bias', 'vision_model.encoder.layers.2.mlp.fc1.weight', 'vision_model.encoder.layers.13.mlp.fc1.bias', 'vision_model.encoder.layers.9.layer_norm2.weight', 'vision_model.encoder.layers.1.mlp.fc1.bias', 'vision_model.encoder.layers.8.self_attn.q_proj.bias', 'vision_model.encoder.layers.14.self_attn.q_proj.weight', 'vision_model.encoder.layers.0.self_attn.out_proj.weight', 'vision_model.encoder.layers.23.mlp.fc1.bias', 'vision_model.encoder.layers.6.self_attn.k_proj.weight', 'vision_model.encoder.layers.1.layer_norm1.weight', 'vision_model.encoder.layers.11.self_attn.k_proj.weight', 'vision_model.encoder.layers.11.mlp.fc2.bias', 'vision_model.encoder.layers.0.layer_norm2.bias', 'vision_model.encoder.layers.17.self_attn.v_proj.bias', 'vision_model.encoder.layers.22.layer_norm2.bias', 'vision_model.encoder.layers.7.mlp.fc2.weight', 'vision_model.encoder.layers.19.layer_norm1.bias', 'vision_model.encoder.layers.9.self_attn.q_proj.bias', 'vision_model.encoder.layers.3.mlp.fc2.bias', 'vision_model.encoder.layers.21.self_attn.v_proj.bias', 'vision_model.encoder.layers.16.layer_norm1.bias', 'vision_model.encoder.layers.16.self_attn.q_proj.weight', 'vision_model.encoder.layers.3.self_attn.q_proj.bias', 'vision_model.encoder.layers.7.self_attn.v_proj.weight', 'vision_model.encoder.layers.15.self_attn.out_proj.weight', 'vision_model.encoder.layers.20.mlp.fc2.weight', 'vision_model.encoder.layers.8.layer_norm1.weight', 'vision_model.encoder.layers.10.self_attn.q_proj.weight', 'vision_model.encoder.layers.12.self_attn.q_proj.bias', 'vision_model.encoder.layers.19.self_attn.out_proj.weight', 'vision_model.encoder.layers.5.self_attn.v_proj.weight', 'vision_model.encoder.layers.5.self_attn.out_proj.weight', 'vision_model.encoder.layers.16.self_attn.q_proj.bias', 'vision_model.encoder.layers.6.self_attn.out_proj.weight', 'vision_model.encoder.layers.7.self_attn.k_proj.weight', 'vision_model.encoder.layers.13.mlp.fc2.weight', 'vision_model.encoder.layers.16.self_attn.v_proj.bias', 'vision_model.pre_layrnorm.weight', 'vision_model.encoder.layers.0.layer_norm2.weight', 'vision_model.encoder.layers.4.layer_norm1.weight', 'vision_model.encoder.layers.19.mlp.fc1.bias', 'vision_model.encoder.layers.13.self_attn.k_proj.bias', 'vision_model.encoder.layers.5.mlp.fc2.bias', 'vision_model.encoder.layers.21.mlp.fc1.weight', 'vision_model.encoder.layers.6.mlp.fc2.bias', 'vision_model.encoder.layers.21.mlp.fc2.weight', 'vision_model.encoder.layers.15.self_attn.k_proj.weight', 'vision_model.encoder.layers.4.mlp.fc1.bias', 'vision_model.encoder.layers.16.layer_norm1.weight', 'vision_model.encoder.layers.22.mlp.fc2.bias', 'vision_model.encoder.layers.22.self_attn.out_proj.bias', 'vision_model.encoder.layers.16.self_attn.v_proj.weight', 'vision_model.encoder.layers.15.layer_norm1.weight', 'vision_model.encoder.layers.22.mlp.fc1.weight', 'vision_model.encoder.layers.13.self_attn.q_proj.bias', 'vision_model.encoder.layers.15.mlp.fc2.bias', 'vision_model.encoder.layers.22.self_attn.v_proj.bias', 'vision_model.encoder.layers.15.mlp.fc1.bias', 'vision_model.encoder.layers.20.layer_norm2.weight', 'vision_model.encoder.layers.0.self_attn.k_proj.weight', 'vision_model.encoder.layers.13.self_attn.q_proj.weight', 'vision_model.encoder.layers.4.self_attn.q_proj.weight', 'vision_model.encoder.layers.21.self_attn.q_proj.bias', 'vision_model.encoder.layers.4.self_attn.k_proj.bias', 'vision_model.encoder.layers.16.mlp.fc1.weight', 'vision_model.encoder.layers.20.mlp.fc2.bias', 'vision_model.encoder.layers.21.self_attn.k_proj.weight', 'vision_model.encoder.layers.7.self_attn.q_proj.bias', 'vision_model.encoder.layers.14.mlp.fc1.weight', 'vision_model.encoder.layers.17.self_attn.k_proj.weight', 'vision_model.encoder.layers.19.self_attn.v_proj.bias', 'vision_model.encoder.layers.14.layer_norm1.bias', 'vision_model.encoder.layers.22.self_attn.k_proj.bias', 'vision_model.encoder.layers.9.self_attn.k_proj.bias', 'vision_model.encoder.layers.18.mlp.fc1.weight', 'vision_model.encoder.layers.3.layer_norm2.weight', 'vision_model.encoder.layers.21.layer_norm2.bias', 'vision_model.encoder.layers.14.layer_norm2.weight', 'vision_model.encoder.layers.8.self_attn.v_proj.weight', 'vision_model.encoder.layers.11.self_attn.q_proj.bias', 'vision_model.encoder.layers.19.self_attn.k_proj.weight', 'vision_model.encoder.layers.17.self_attn.q_proj.bias', 'vision_model.encoder.layers.1.self_attn.out_proj.bias', 'vision_model.encoder.layers.10.mlp.fc1.weight', 'vision_model.encoder.layers.22.self_attn.v_proj.weight', 'vision_model.encoder.layers.10.self_attn.out_proj.weight', 'vision_model.encoder.layers.5.self_attn.out_proj.bias', 'vision_model.pre_layrnorm.bias', 'vision_model.encoder.layers.5.mlp.fc1.weight', 'vision_model.encoder.layers.9.layer_norm2.bias', 'vision_model.encoder.layers.18.self_attn.v_proj.bias', 'vision_model.encoder.layers.2.layer_norm1.bias', 'vision_model.encoder.layers.18.mlp.fc1.bias', 'vision_model.encoder.layers.9.self_attn.v_proj.weight', 'vision_model.encoder.layers.3.self_attn.out_proj.bias', 'vision_model.encoder.layers.6.layer_norm1.bias', 'vision_model.encoder.layers.23.mlp.fc2.weight', 'vision_model.encoder.layers.4.self_attn.v_proj.weight', 'vision_model.encoder.layers.17.layer_norm2.bias', 'vision_model.encoder.layers.2.self_attn.out_proj.bias', 'vision_model.encoder.layers.15.self_attn.v_proj.weight', 'vision_model.encoder.layers.20.mlp.fc1.weight', 'vision_model.encoder.layers.21.self_attn.v_proj.weight', 'vision_model.encoder.layers.23.layer_norm2.weight', 'vision_model.encoder.layers.9.mlp.fc1.bias', 'vision_model.encoder.layers.22.mlp.fc2.weight', 'vision_model.encoder.layers.0.mlp.fc2.weight', 'vision_model.encoder.layers.4.mlp.fc2.weight', 'vision_model.encoder.layers.8.mlp.fc1.weight', 'vision_model.encoder.layers.10.layer_norm1.weight', 'vision_model.encoder.layers.10.layer_norm2.weight', 'visual_projection.weight', 'vision_model.encoder.layers.3.self_attn.k_proj.bias', 'vision_model.encoder.layers.17.mlp.fc2.bias', 'vision_model.encoder.layers.6.layer_norm2.weight', 'vision_model.encoder.layers.12.mlp.fc2.bias', 'vision_model.encoder.layers.11.self_attn.v_proj.bias', 'vision_model.encoder.layers.19.mlp.fc1.weight', 'vision_model.encoder.layers.10.self_attn.k_proj.bias', 'vision_model.encoder.layers.12.self_attn.q_proj.weight', 'vision_model.encoder.layers.22.layer_norm1.bias', 'vision_model.encoder.layers.3.self_attn.q_proj.weight', 'text_projection.weight', 'vision_model.encoder.layers.5.self_attn.k_proj.bias', 'vision_model.encoder.layers.22.layer_norm1.weight', 'vision_model.encoder.layers.2.layer_norm2.weight', 'vision_model.encoder.layers.11.self_attn.out_proj.bias', 'vision_model.encoder.layers.4.layer_norm2.bias', 'vision_model.encoder.layers.12.mlp.fc1.weight', 'vision_model.encoder.layers.9.self_attn.out_proj.bias', 'vision_model.encoder.layers.10.mlp.fc2.bias', 'vision_model.encoder.layers.15.self_attn.q_proj.bias', 'vision_model.embeddings.class_embedding', 'vision_model.encoder.layers.16.layer_norm2.bias', 'vision_model.encoder.layers.19.self_attn.q_proj.weight', 'vision_model.encoder.layers.23.self_attn.k_proj.bias', 'vision_model.encoder.layers.3.self_attn.v_proj.weight', 'vision_model.encoder.layers.15.layer_norm1.bias', 'vision_model.encoder.layers.3.mlp.fc2.weight', 'vision_model.encoder.layers.23.self_attn.out_proj.bias', 'vision_model.encoder.layers.2.self_attn.v_proj.weight', 'vision_model.encoder.layers.14.mlp.fc1.bias', 'vision_model.encoder.layers.17.self_attn.k_proj.bias', 'vision_model.encoder.layers.19.mlp.fc2.weight', 'vision_model.encoder.layers.11.mlp.fc2.weight', 'vision_model.encoder.layers.7.self_attn.out_proj.weight', 'vision_model.encoder.layers.12.layer_norm2.bias']\n",
            "- This IS expected if you are initializing CLIPTextModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing CLIPTextModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([18432])\n",
            "tensor([-0.3884,  0.0229, -0.0522,  ...,  0.9513,  0.5738, -1.0634],\n",
            "       grad_fn=<ReshapeAliasBackward0>)\n",
            "finish\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from scipy.linalg import pinv\n",
        "\n",
        "# Define the ELM autoencoder class\n",
        "class ELM_Autoencoder(torch.nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(ELM_Autoencoder, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.weight = torch.randn(input_size, hidden_size)\n",
        "        self.bias = torch.randn(hidden_size)\n",
        "        self.activation_hidden = torch.nn.ReLU()\n",
        "        self.activation_output = torch.nn.Identity()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Encoder\n",
        "        h = self.activation_hidden(x.float() @ self.weight + self.bias)\n",
        "        # Decoder\n",
        "        y = self.activation_output(h @ self.weight.t() + self.bias)\n",
        "        return y, h\n",
        "\n",
        "# Load data\n",
        "data = load_digits()\n",
        "X = data['data'].astype(float)\n",
        "y = data['target']\n",
        "\n",
        "# Standardize input data\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define hyperparameters\n",
        "input_size = X.shape[1]\n",
        "hidden_size = 200\n",
        "output_size = 768\n",
        "alpha = 1e-6\n",
        "\n",
        "# Initialize ELM autoencoder\n",
        "model = ELM_Autoencoder(input_size, hidden_size, output_size)\n",
        "\n",
        "# Compute output weights\n",
        "with torch.no_grad():\n",
        "    X_train = torch.tensor(X_train)\n",
        "    X_test = torch.tensor(X_test)\n",
        "    Y_train = torch.randn(X_train.shape[0], output_size)\n",
        "    Y_test = torch.randn(X_test.shape[0], output_size)\n",
        "    _, H_train = model(X_train)\n",
        "    output_weights = pinv(H_train) @ Y_train\n",
        "\n",
        "# Fit ELM autoencoder\n",
        "with torch.no_grad():\n",
        "    H_train = model.activation_hidden(torch.tensor(X_train).float() @ model.weight + model.bias)\n",
        "    H_test = model.activation_hidden(torch.tensor(X_test).float() @ model.weight + model.bias)\n",
        "    Y_train = model.activation_output(H_train @ output_weights)\n",
        "    Y_test = model.activation_output(H_test @ output_weights)\n",
        "\n",
        "# Print training and testing accuracy\n",
        "print(\"Training accuracy: \", np.mean(np.square(Y_train.numpy() - X_train)))\n",
        "print(\"Testing accuracy: \", np.mean(np.square(Y_test.numpy() - X_test)))\n"
      ],
      "metadata": {
        "id": "maYFj9jmz-dm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "outputId": "85ecf19e-5995-437f-81af-617d669cea03"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-bab7a82e1dfa>\u001b[0m in \u001b[0;36m<cell line: 49>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mY_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mY_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m     \u001b[0moutput_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpinv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mH_train\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-bab7a82e1dfa>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;31m# Decoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (64) must match the size of tensor b (200) at non-singleton dimension 1"
          ]
        }
      ]
    }
  ]
}